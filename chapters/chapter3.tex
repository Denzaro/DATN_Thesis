\chapter{THIẾT KẾ HỆ THỐNG}

\section{YÊU CẦU CỦA HỆ THỐNG}
Hệ thống được đề xuất hướng tới việc mô phỏng, dự báo và điều tiết giao thông dựa trên dữ liệu hình ảnh snapshot thu thập từ camera giao thông, kết hợp các kỹ thuật học sâu và mô phỏng giao thông vi mô. Để đáp ứng mục tiêu nghiên cứu và đảm bảo khả năng triển khai thực tế, hệ thống cần thỏa mãn các yêu cầu chức năng và phi chức năng sau.

Về giai đoạn thu thập dữ liệu, hệ thống cần đảm bảo các yêu cầu sau:
\begin{itemize}
    \item Tiếp nhận được dữ liệu hình ảnh giao thông dạng snapshot từ các camera giao thông đặt tại các nút giao.
    \item Các ảnh này phải được quản lý, lưu trữ và gắn nhãn thời gian rõ ràng.
\end{itemize}

Về giai đoạn tiền xử lý dữ liệu, nhận diện và đếm phương tiện, hệ thống cần đáp ứng các yêu cầu sau:
\begin{itemize}
    \item Các ảnh đầu vào cần được thực hiện các bước xử lý ảnh cơ bản như tăng độ phân giải, giảm nhiễu và chuẩn hóa kích thước.
    \item Hệ thống tích hợp mô hình YOLOv11 nhằm nhận diện các phương tiện giao thông chính trên từng ảnh snapshot, trong đó các phương tiện được quy ước và phân loại thành hai nhóm: xe hai bánh (xe máy) và xe bốn bánh (xe hơi).
    \item Kết quả phát hiện bao gồm số lượng phương tiện theo từng loại tại mỗi thời điểm và tại từng địa điểm giám sát cụ thể, trong đó “địa điểm” được hiểu là vị trí camera đại diện cho một khu vực giao thông trên bản đồ.
    \item Lưu trữ kết quả đếm phương tiện với timestamp và vị trí tương ứng để phục vụ cho các bước xử lý tiếp theo.
    \item Đảm bảo độ chính xác cao trong việc nhận diện và đếm phương tiện, với sai số không vượt quá $5\%$ so với thực tế.
\end{itemize}

Tiếp đến là yêu cầu về mô phỏng giao thông:
\begin{itemize}
    \item None
\end{itemize}

Đối với giai đoạn xây dựng chuỗi thời gian và dự báo lưu lượng giao thông, hệ thống cần thỏa mãn các yêu cầu sau:
\begin{itemize}
    \item None
\end{itemize}

Đối với giai đoạn tích hợp và điều khiển luồng giao thông, hệ thống cần đáp ứng các yêu cầu sau:
\begin{itemize}
    \item Hệ thống tích hợp các giá trị dự báo từ LSTM vào môi trường mô phỏng giao thông SUMO, trong đó lưu lượng phương tiện, tốc độ dòng xe hoặc phân bố phương tiện tại các nút giao được điều chỉnh tương ứng với trạng thái giao thông dự kiến.
    \item None
\end{itemize}

Cuối cùng, về giai đoạn trực quan hóa và phân tích, hệ thống cần:
\begin{itemize}
    \item Cung cấp giao diện trực quan để hiển thị kết quả nhận diện, đếm phương tiện, dự báo lưu lượng và mô phỏng giao thông.
    \item Hỗ trợ các biểu đồ, bản đồ nhiệt và các công cụ phân tích để người dùng có thể dễ dàng hiểu và đánh giá tình hình giao thông. 
     \item So sánh hiệu quẩ giữa việc xử dụng chiến lược điều tiết và không sử dụng để đánh giá hiệu quả của các biện pháp điều tiết dựa trên các chỉ số: thời gian di chuyển trung bình, thời gian đợi, chiều dài hàng đợi.
\end{itemize}

\section{KIẾN TRÚC HỆ THỐNG}
\subsection{Sơ đồ khối hệ thống}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.6\textheight, keepaspectratio]{fig/system_block_diagram.png}
    \caption{Sơ đồ khối kiến trúc hệ thống}
    \label{fig:system_block_diagram}
\end{figure}

\textbf{Chức năng từng khối: }
\begin{itemize}
    \item \textbf{Khối thu thập dữ liệu: } Khối thu thập dữ liệu chịu trách nhiệm tiếp nhận các hỉnh ảnh snapshot từ nguồn mở Open Street Map (OSM). Trong đề tài này, dữ liệu không được thu thập trực tiếp từ hệ thống camera vật lý mà được lấy từ nguồn dữ liệu mở, nơi các camera giao thông đã được thiết lập và công bố sẵn cho mục đích quan sát và tham khảo. Quá trình thu thập dữ liệu được thực hiện thông qua truy suất tự động (web scraping) để tải về các hình ảnh snapshot tại các thời điểm xác định (khoảng 12 giây một ảnh). 
    \item \textbf{Khối lưu trữ: } Khối lưu trữ đóng vai trò quản lý và tổ chức toàn bộ dữ liệu hình ảnh thu thập được cũng như các dữ liệu trung gian phát sinh trong quá trình xử lý. Các ảnh snapshot thu thập từ camera phía OSM được lưu trữ dưới dạng cấu trúc thư mục phân cấp trên hệ thống lưu trữ tệp tin đám mây Google Drive. Mỗi ảnh được gắn nhãn thời gian rõ ràng và sắp xếp theo từng thư mục tương ứng với địa điểm giám sát, nhằm đảm bảo tính nhất quán và thuận tiện cho việc truy xuất, xử lý và phân tích về sau. Bên cạnh đó, các ảnh kết quả sau khi nhận diện và đếm phương tiện, dữ liệu thống kê mật độ giao thông theo thời gian, cũng như dữ liệu đầu vào và đầu ra của mô hình LSTM đều được lưu trữ tập trung tại khối này.
    \item \textbf{Khối tiền xử lý ảnh: } Khối tiền xử lý ảnh đảm nhiệm việc thực hiện các phép biến đổi cần thiết nhằm cải thiện chất lượng dữ liệu hình ảnh trước khi đưa vào mô hình nhận diện. Nguyên nhân là do các ảnh snapshot thu thập từ camera giao thông công khai trên mạng thường có chất lượng không đồng đều, chịu ảnh hưởng bởi nhiều yếu tố như độ phân giải thấp, nhiễu ảnh, điều kiện ánh sáng không ổn định và góc chụp chưa tối ưu. Do đó, khối này áp dụng một số kỹ thuật xử lý ảnh cơ bản, bao gồm tăng cường độ phân giải (super-resolution), lọc nhiễu (denoising), chuẩn hóa kích thước ảnh (resizing) và chia nhỏ ảnh nhằm đảm bảo dữ liệu đầu vào cho mô hình nhận diện đạt chất lượng tốt hơn và có tính nhất quán, dễ dàng nhận diện.
    \item \textbf{Khối nhận diện và phân tích phương tiện: } Khối nhận diện và phân tích phương tiện sử dụng mô hình học sâu YOLOv11 để thực hiện phát hiện và phân loại các phương tiện giao thông xuất hiện trong từng ảnh snapshot. Mô hình được khởi tạo từ trọng số huấn luyện sẵn (pre-trained) trên các tập dữ liệu lớn và đa dạng, nhờ đó có khả năng nhận diện hiệu quả các loại phương tiện phổ biến. Tuy nhiên, nhằm đơn giản hóa bài toán và phù hợp với mục tiêu nghiên cứu, các phương tiện được quy ước và gom nhóm thành hai lớp chính, bao gồm xe hai bánh (đại diện cho xe máy) và xe bốn bánh (đại diện cho xe hơi). Bên cạnh đó, do chất lượng hình ảnh thu thập từ camera giao thông còn hạn chế và các bước tiền xử lý không thể khắc phục hoàn toàn các yếu tố bất lợi như góc quay cao, góc quay xiên hoặc mật độ giao thông lớn, một số phương tiện đặc biệt là xe máy có thể bị che khuất hoặc chồng chéo, dẫn đến độ chính xác nhận diện suy giảm. Để khắc phục vấn đề này, khối xử lý còn tích hợp các thuật toán xử lý ảnh bổ sung như Polygon Fill, Rectangle Fill, Pixel-wise Logic và Non-zero Pixel Count nhằm tính toán tỷ lệ che phủ của xe máy trong các vùng quan tâm. Trên cơ sở đó, số lượng xe máy trong từng vùng được ước lượng, góp phần nâng cao độ chính xác tổng thể của quá trình đếm phương tiện.
    \item \textbf{Khối dự báo lưu lượng và điều chỉnh tín hiệu đèn giao thông: } None
    \item \textbf{Khối mô phỏng: } None
    \item \textbf{Khối hiển thị và đánh giá kết quả: } None
\end{itemize}

\subsection{Thiết kế khối thu thập dữ liệu}
None
\subsection{Thiết kế khối lưu trữ}
Khối lưu trữ dữ liệu đóng vai trò tiếp nhận, tổ chức và quản lý toàn bộ dữ liệu trong hệ thống, bao gồm ảnh snapshot thu thập từ camera giao thông, dữ liệu sau tiền xử lý, kết quả nhận diện - đếm phương tiện, cũng như các tập dữ liệu đầu vào/đầu ra phục vụ mô phỏng và dự báo. Trong đề tài này, Google Drive được sử dụng như một nền tảng lưu trữ đám mây, đáp ứng yêu cầu về dung lượng, khả năng truy cập linh hoạt và thuận tiện cho việc chia sẻ, sao lưu dữ liệu trong quá trình nghiên cứu.

Việc sử dụng Google Drive cho phép hệ thống tách biệt hoàn toàn giữa khâu xử lý và khâu lưu trữ, từ đó giảm phụ thuộc vào hạ tầng máy chủ cục bộ và tăng tính linh hoạt trong quá trình mở rộng hoặc thay đổi môi trường triển khai. Khối lưu trữ không thực hiện các chức năng xử lý dữ liệu phức tạp mà chỉ đảm nhiệm vai trò lưu trữ tệp và cung cấp dữ liệu cho các khối xử lý tiếp theo thông qua các script truy xuất tự động.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.5\textheight, keepaspectratio]{fig/file_structure.png}
    \caption[Cấu trúc lưu trữ dữ liệu trên Google Drive]{Cấu trúc lưu trữ dữ liệu trên Google Drive}
    \label{fig:file_structure}
\end{figure}

Như trên hình \ref{fig:file_structure}, dữ liệu được tổ chức theo mô hình cây phân cấp, trong đó:
\begin{itemize}
    \item \textbf{DATN\_Image\_Traffic:} 
    Thư mục chủ đạo chứa dữ liệu đầu vào thô và dữ liệu đã qua xử lý, chia làm hai nhánh chính:
    
    \begin{itemize}
        \item \textbf{Raw Images:} 
        Dữ liệu đầu vào thu thập trực tiếp từ camera giao thông (giaothong.hochiminhcity.gov.vn). Cấu trúc gồm:
        \begin{itemize}
            \item \textbf{Location Folder:} Tên thư mục theo địa điểm thực tế (Ví dụ: \texttt{Nga\_Tu\_So}, \texttt{Cau\_Giay}).
            \item \textbf{Date Folder:} Phân loại theo ngày thu thập (Định dạng: \texttt{YYYY-MM-DD}).
            \item \textbf{Hour Folder:} Phân loại theo khung giờ (Ví dụ: \texttt{01h}, \texttt{02h}...).
            \item \textbf{[Unix\_Timestamp].jpg:} Các tệp ảnh gốc với tên là Unix Timestamp để đảm bảo tính duy nhất và tự động sắp xếp theo thời gian.
        \end{itemize}

        \item \textbf{Results:} 
        Lưu trữ kết quả sau khi xử lý/nhận diện, duy trì cấu trúc tương tự nhánh Raw Images để dễ dàng đối chiếu:
        \begin{itemize}
            \item \textbf{[Unix\_Timestamp].csv:} Tệp tin chứa nhãn (labels) hoặc metadata tương ứng với ảnh gốc.
            \item \textbf{[Hour].rar:} Tệp nén toàn bộ dữ liệu của khung giờ đó để tối ưu lưu trữ.
            \item \textbf{[YYYYMMDD\_HHmmss].jpg:} Ảnh kết quả (đã vẽ bounding box...) đặt tên theo định dạng thời gian truyền thống để người dùng dễ đọc bằng mắt thường.
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Thiết kế khối tiền xử lý ảnh}
Khối tiền xử lý ảnh có vai trò chuẩn hóa và nâng cao chất lượng đầu vào trước khi đưa vào khối nhận diện và phân tích phương tiện. Hệ thống thực hiện các bước tiền xử lý chính sau:
\begin{enumerate}
    \item \textbf{Tăng cường độ phân giải và chuẩn hóa kích thước ảnh: } Sử dụng Real-ESRGAN để nâng cao độ phân giải và giảm nhiễu cho các ảnh snapshot, ngoài ra còn tăng kích thước ảnh về chuẩn cố định nhằm đảm bảo tính nhất quán và cải thiện khả năng nhận diện của mô hình học sâu.
    \item \textbf{Chia đều ảnh thành các phần: }Ảnh sau khi được nâng cao chất lượng được chia thành bốn vùng con có kích thước bằng nhau. Việc chia nhỏ ảnh giúp mô hình tập trung tốt hơn vào các đặc trưng cục bộ, từ đó nâng cao độ chính xác trong việc phát hiện phương tiện, đặc biệt trong các tình huống mật độ giao thông cao hoặc khi các đối tượng bị che khuất một phần.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/upscale_image.png}
    \caption[Lưu đồ quá trình tiền xử lý ảnh]{Lưu đồ chi tiết quá trình tiền xử lý ảnh}
    \label{fig:upscale_image}
\end{figure}

Giải thích lưu đồ tiền xử lý ảnh ở hình \ref{fig:upscale_image}: \\
\hspace*{1cm} Ảnh đầu vào trước hết được đưa vào mô hình Real-ESRGAN đã được huấn luyện sẵn (pre-trained model) với các tham số cấu hình gồm hệ số phóng đại $scale=2$, mô hình \textit{RealESRGAN\_x2plus}, thiết bị xử lý \textit{cuda} và chế độ tính toán bán chính xác \textit{fp16}.

Sau khi quá trình nâng cao độ phân giải hoàn tất, chất lượng ảnh đầu ra được đánh giá thông qua việc tính toán giá trị độ sáng trung bình của các pixel trong ảnh. 
Nếu giá trị này nhỏ hơn một ngưỡng xác định (cụ thể là 5), ảnh được xem là không hợp lệ do quá tối và có khả năng phát sinh lỗi trong quá trình upscale. 
Trong trường hợp này, hệ thống tiến hành thực hiện lại bước nâng cao độ phân giải với cấu hình tương tự, nhưng chuyển sang chế độ tính toán toàn chính xác (\textit{fp32}) nhằm tăng độ ổn định và độ chính xác của kết quả.

Ngược lại, nếu ảnh đầu ra đạt yêu cầu về độ sáng, ảnh sẽ được chia thành bốn vùng con có kích thước bằng nhau. 
Quá trình này được thực hiện bằng cách xác định tọa độ trung điểm theo chiều rộng và chiều cao của ảnh, từ đó cắt ảnh thành bốn phần tương ứng với các góc \textit{Top-Left}, \textit{Top-Right}, \textit{Bottom-Left} và \textit{Bottom-Right}.

Cuối cùng, các ảnh con sau khi chia không được lưu dưới dạng các tệp ảnh riêng lẻ, mà được lưu trữ dưới dạng các giá trị trong bộ nhớ cùng với các id để nhận biết được các phần ảnh để phục vụ cho quá trình nhận diện và phân tích phuwogn tiện ở khối tiếp theo.

\subsection{Thiết kế khối nhận diện và phân tích phương tiện}
Khối nhận diện và phân tích phương tiện sử dụng mô hình học sâu YOLOv11 đã được huấn luyện trước trên dataset COCO (pre-trained model) để phát hiện và phân loại các phương tiện giao thông trong từng ảnh snapshot. Tuy nhiên, bởi vì dữ liệu đầu vào có chất lượng không tốt, góc quay không tối ưu và mật độ giao thông cao, việc nhận diện chính xác các phương tiện, đặc biệt là xe máy trở nên khó khăn. Do đó, ngoài việc sử dụng mô hình YOLOv11 để phát hiện và phân loại phương tiện thì cần có thêm các bước xử lý ảnh bổ sung nhằm nâng nâng cao độ chính xác trong việc đếm xe máy, tính toán tỷ lệ che phủ của xe máy trong các vùng quan tâm (ROI - Region of Interest).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/vehicle_detector.png}
    \caption[Lưu đồ quá trình nhận diện và đếm phương tiện]{Lưu đồ quá trình nhận diện và đếm phương tiện}
    \label{fig:vehicle_detector}
\end{figure}

Giải thích lưu đồ nhận diện và đếm phương tiện ở hình \ref{fig:vehicle_detector}: \\
\hspace*{1cm} Khối này bắt đầu bằng việc tiếp nhận chính xác bốn ảnh con đã được tiền xử lý từ khối trước và tiến hành xử lý lần lượt từng ảnh. Trước hết, hệ thống kiểm tra xem ảnh con đầu vào có thuộc danh sách các Tile ID được cấu hình phân vùng ROI (Region of Interest) hay không. Nếu ảnh không nằm trong danh sách này, ảnh sẽ được đưa trực tiếp vào mô hình YOLOv11 để thực hiện phát hiện và phân loại các phương tiện, bao gồm xe hai bánh và xe bốn bánh. Ngược lại, nếu ảnh con thuộc một Tile ID có cấu hình phân vùng ROI, ảnh sẽ được xử lý bổ sung bằng các thuật toán xử lý ảnh nhằm ước lượng số lượng xe máy trong vùng quan tâm, đồng thời vẫn thực hiện nhận diện phương tiện bằng mô hình YOLOv11.
Sau khi hoàn tất quá trình xử lý đối với cả bốn ảnh con, các kết quả đếm phương tiện theo từng phần ảnh được tổng hợp lại.
Hệ thống tiếp tục kiểm tra sự trùng lặp của các phương tiện xuất hiện tại vùng rìa giữa các ảnh con và loại bỏ các trường hợp bị đếm trùng. Cuối cùng, kết quả tổng hợp được lưu trữ dưới dạng tệp csv. Đồng thời, các ảnh con được ghép lại để tạo thành ảnh kết quả, trong đó các phương tiện được phát hiện được biểu diễn bằng các bounding box, kèm theo phần che phủ của xe máy trong các vùng phân đoạn (nếu có).

Đối với việc chọn vùng quan tâm (ROI) để ước lượng số lượng xe máy thì trong đề tài này chỉ lựa chọn các vùng có mật độ xe máy cao và thường bị che khuất trong ảnh snapshot gốc. Các vùng phân đoạn được xác định thông qua một công cụ hỗ trợ được xây dựng riêng bằng Python. Công cụ này cho phép người vận hành khoanh vùng các khu vực cần khai thác trên ảnh,sau đó xuất ra tọa độ các điểm biên của vùng ROI theo hệ tọa độ pixel của ảnh. Các tọa độ ROI được biểu diễn dưới dạng các cặp điểm $(x, y)$ trong hệ tọa độ ảnh, tuân theo quy ước của thư viện OpenCV, với gốc tọa độ nằm tại góc trên bên trái ảnh. Những thông tin này được lưu trữ trong tệp cấu hình YAML tương ứng với từng địa điểm và được hệ thống sử dụng trong quá trình xử lý và phân tích ảnh như hình \ref{fig:segment_config}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/segment_config.png}
    \caption[Cấu trúc file YAML cấu hình vùng quan tâm (ROI)]{Cấu trúc file YAML cấu hình vùng quan tâm (ROI)}
    \label{fig:segment_config}
\end{figure}

Ngoài ra đối với các vùng có vật cản hoặc có yếu tố gây nhiễu trong vùng segment như bóng cây, biển quảng cáo, cột đèn... thì trong đề tài này còn cấu hình thêm các ROI để loại bỏ các yếu tố nhiễu này nhằm tránh ảnh hưởng đến kết quả đếm phương tiện như \textit{exclusion\_zones} trên hình \ref{fig:segment_config}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/process_quadrant_1.png}
    \caption[Lưu đồ xử lý từng ảnh con]{Lưu đồ xử lý từng ảnh con}
    \label{fig:process_quadrant}
\end{figure}

Giải thích lưu đồ xử lý từng ảnh con ở hình \ref{fig:process_quadrant}: \\
\hspace*{1cm}Trước hết, hệ thống nạp cấu hình phân vùng ROI (Region of Interest) từ tệp YAML đã được trình bày ở phần trước. Tiếp theo, mỗi ảnh con đầu vào được kiểm tra xem ID của phần ảnh đó có nằm trong danh sách các vùng được cấu hình ROI hay không.

Trong trường hợp ảnh con không thuộc danh sách ROI, ảnh sẽ được đưa trực tiếp vào mô hình YOLOv11 để thực hiện phát hiện và phân loại phương tiện. Ngược lại, nếu ảnh con thuộc vùng có cấu hình ROI, các tham số tương ứng như ngưỡng tin cậy (confidence threshold), ngưỡng IOU và tọa độ vùng quan tâm sẽ được trích xuất từ cấu hình để phục vụ cho các bước xử lý tiếp theo.

Tại giai đoạn này, mô hình YOLOv11 chỉ được sử dụng để phát hiện phương tiện bốn bánh. Đối với phương tiện hai bánh, hệ thống không áp dụng trực tiếp phương pháp phát hiện dựa trên bounding box do đặc thù kích thước nhỏ, mật độ cao và hiện tượng che khuất phổ biến, dẫn đến độ chính xác thấp, số lượng phát hiện không ổn định và kết quả trực quan không phản ánh đúng mật độ thực tế trong vùng quan tâm.

Thay vào đó, số lượng xe hai bánh được ước lượng gián tiếp thông qua tỷ lệ che phủ trong vùng ROI. Cụ thể, hệ thống áp dụng một số kỹ thuật xử lý ảnh bao gồm: Polygon Fill, Rectangle Fill, các phép toán logic theo pixel và đếm số pixel khác không (Non-zero Pixel Count) nhằm xác định tỷ lệ diện tích bị che phủ bởi xe máy trong vùng quan tâm. Trên cơ sở tỷ lệ che phủ này, số lượng xe hai bánh được ước lượng tương ứng.

Cuối cùng, kết quả đếm phương tiện hai bánh và bốn bánh, tỷ lệ che phủ của xe máy, cùng với ảnh trực quan hóa được lưu trữ trong bộ nhớ sẽ được tổng hợp và trả về cho khối xử lý chính của hệ thống.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/segment_detection.png}
    \caption[Lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI]{Lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI}
    \label{fig:segment_detection}
\end{figure}

Giải thích lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI ở hình \ref{fig:segment_detection}: \\
\hspace*{1cm} Đầu tiên, hệ thống sẽ tạo mặt nạ nhị phân cho vùng ROI dạng đa giác từ các tọa độ được lấy từ tệp cấu hình YAML. 


