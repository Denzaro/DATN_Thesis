\chapter{THIẾT KẾ HỆ THỐNG}

\section{YÊU CẦU CỦA HỆ THỐNG}
Hệ thống được đề xuất hướng tới việc mô phỏng, dự báo và điều chỉnh tính hiệu đèn giao thông dựa trên dữ liệu hình ảnh snapshot thu thập từ camera giao thông, kết hợp các kỹ thuật học sâu và mô phỏng giao thông vi mô. Để đáp ứng mục tiêu nghiên cứu và đảm bảo khả năng triển khai thực tế, hệ thống cần thỏa mãn các yêu cầu chức năng và phi chức năng sau.

Về giai đoạn thu thập dữ liệu, hệ thống cần đảm bảo các yêu cầu sau:
\begin{itemize}
    \item Tiếp nhận được dữ liệu hình ảnh giao thông dạng snapshot từ các camera giao thông đặt tại các nút giao.
    \item Các ảnh này phải được quản lý, lưu trữ và gắn nhãn thời gian rõ ràng.
\end{itemize}

Về giai đoạn tiền xử lý dữ liệu, nhận diện và đếm phương tiện, hệ thống cần đáp ứng các yêu cầu sau:
\begin{itemize}
    \item Các ảnh đầu vào cần được thực hiện các bước xử lý ảnh cơ bản như tăng độ phân giải, giảm nhiễu và chuẩn hóa kích thước.
    \item Hệ thống tích hợp mô hình YOLOv11 nhằm nhận diện các phương tiện giao thông chính trên từng ảnh snapshot, trong đó các phương tiện được quy ước và phân loại thành hai nhóm: xe hai bánh (xe máy) và xe bốn bánh (xe hơi). Ngoài ra, đối với các địa điểm có mật độ giao thông cao, hệ thống cần bổ sung các thuật toán xử lý ảnh để ước lượng số lượng xe máy dựa trên tỷ lệ che phủ trong các vùng quan tâm (ROI).
    \item Kết quả phát hiện bao gồm số lượng phương tiện theo từng loại tại mỗi thời điểm và tại từng địa điểm giám sát cụ thể, trong đó “địa điểm” được hiểu là vị trí camera đại diện cho một khu vực giao thông trên bản đồ.
    \item Lưu trữ kết quả đếm phương tiện với timestamp và vị trí tương ứng để phục vụ cho các bước xử lý tiếp theo.
\end{itemize}

Tiếp đến là yêu cầu về mô phỏng giao thông:
\begin{itemize}
    \item Khả năng xây dựng mạng lưới giao thông mô phỏng tương ứng với khu vực thực tế từ dữ liệu OpenStreetMap (OSM).
    \item Tái hiện luồng phương tiện (xe hai bánh và xe bốn bánh) với lưu lượng biến thiên theo thời gian dựa trên các giá trị thực tế.
    \item Hỗ trợ lập trình điều khiển tín hiệu đèn giao thông thông qua giao diện TraCI của SUMO.
\end{itemize}

Đối với giai đoạn xây dựng chuỗi thời gian và dự báo lưu lượng giao thông, hệ thống cần thỏa mãn các yêu cầu sau:
\begin{itemize}
    \item Phát hiện và gán nhãn tắc nghẽn từ dữ liệu lưu lượng giao thông thu thập.
    \item Chuẩn hóa dữ liệu đầu vào để phù hợp với các mô hình học máy.
    \item Xây dựng chuỗi thời gian từ dữ liệu gốc bằng phương pháp cửa sổ trượt.
    \item Huấn luyện mô hình dự báo có khả năng phát hiện xu hướng tắc nghẽn trong tương lai.
    \item Đảm bảo sai số dự báo nằm trong ngưỡng chấp nhận được.
\end{itemize}

Đối với giai đoạn tích hợp và điều khiển tín hiệu đèn giao thông, hệ thống cần đáp ứng các yêu cầu sau:
\begin{itemize}
    \item Tích hợp kết quả dự báo vào môi trường mô phỏng SUMO.
    \item Hỗ trợ điều chỉnh chương trình đèn tín hiệu dựa trên dữ liệu dự báo.
    \item Cung cấp giao diện để giao tiếp giữa mô hình dự báo và công cụ mô phỏng (TraCI).
\end{itemize}

Cuối cùng, về giai đoạn trực quan hóa và phân tích, hệ thống cần:
\begin{itemize}
    \item Cung cấp giao diện trực quan để hiển thị kết quả nhận diện, đếm phương tiện, dự báo lưu lượng và mô phỏng giao thông.
    \item Hỗ trợ các biểu đồ, bản đồ nhiệt và các công cụ phân tích để người dùng có thể dễ dàng hiểu và đánh giá tình hình giao thông. 
     \item So sánh hiệu quả giữa việc xử dụng chiến lược điều chỉnh tín hiệu đèn giao thông và không sử dụng để đánh giá hiệu quả của các biện pháp điều tiết dựa trên các chỉ số: thời gian di chuyển trung bình, thời gian đợi, chiều dài hàng đợi.
\end{itemize}

\section{KIẾN TRÚC HỆ THỐNG}
\subsection{Sơ đồ khối hệ thống}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.8\textheight, keepaspectratio]{fig/system_block_diagram.png}
    \caption{Sơ đồ khối kiến trúc hệ thống}
    \label{fig:system_block_diagram}
\end{figure}

\textbf{Chức năng từng khối: }
\begin{itemize}
    \item \textbf{Khối thu thập dữ liệu: } Khối thu thập dữ liệu chịu trách nhiệm tiếp nhận các hỉnh ảnh snapshot từ nguồn mở (Cổng thông tin giao thông thành phố Hồ Chí Minh). Trong đề tài này, dữ liệu không được thu thập trực tiếp từ hệ thống camera vật lý mà được lấy từ nguồn dữ liệu mở, nơi các camera giao thông đã được thiết lập và công bố sẵn cho mục đích quan sát và tham khảo. Quá trình thu thập dữ liệu được thực hiện thông qua truy suất tự động (web scraping) để tải về các snapshot tại các thời điểm xác định (khoảng 12 giây một ảnh). 
    \item \textbf{Khối lưu trữ: } Khối lưu trữ đóng vai trò quản lý và tổ chức toàn bộ dữ liệu hình ảnh thu thập được cũng như các dữ liệu trung gian phát sinh trong quá trình xử lý. Các ảnh snapshot thu thập từ camera phía website được lưu trữ dưới dạng cấu trúc thư mục phân cấp trên hệ thống lưu trữ tệp tin đám mây Google Drive. Mỗi ảnh được gắn nhãn thời gian rõ ràng và sắp xếp theo từng thư mục tương ứng với địa điểm giám sát, nhằm đảm bảo tính nhất quán và thuận tiện cho việc truy xuất, xử lý và phân tích về sau. Bên cạnh đó, các ảnh kết quả sau khi nhận diện và đếm phương tiện, dữ liệu thống kê mật độ giao thông theo thời gian, cũng như dữ liệu đầu vào của mô hình LSTM đều được lưu trữ tập trung tại khối này.
    \item \textbf{Khối tiền xử lý ảnh: } Khối tiền xử lý ảnh đảm nhiệm việc thực hiện các phép biến đổi cần thiết nhằm cải thiện chất lượng dữ liệu hình ảnh trước khi đưa vào mô hình nhận diện. Nguyên nhân là do các ảnh snapshot thu thập từ camera giao thông công khai trên mạng thường có chất lượng không đồng đều, chịu ảnh hưởng bởi nhiều yếu tố như độ phân giải thấp, nhiễu ảnh, điều kiện ánh sáng không ổn định và góc chụp chưa tối ưu. Do đó, khối này áp dụng một số kỹ thuật xử lý ảnh cơ bản, bao gồm tăng cường độ phân giải (super-resolution), lọc nhiễu (denoising), chuẩn hóa kích thước ảnh (resizing) và chia nhỏ ảnh nhằm đảm bảo dữ liệu đầu vào cho mô hình nhận diện đạt chất lượng tốt hơn và có tính nhất quán, dễ dàng nhận diện.
    \item \textbf{Khối nhận diện và phân tích phương tiện: } Khối nhận diện và phân tích phương tiện sử dụng mô hình học sâu YOLOv11 để thực hiện phát hiện và phân loại các phương tiện giao thông xuất hiện trong từng ảnh snapshot. Mô hình được khởi tạo từ trọng số huấn luyện sẵn (pre-trained) trên các tập dữ liệu lớn và đa dạng, nhờ đó có khả năng nhận diện hiệu quả các loại phương tiện phổ biến. Tuy nhiên, nhằm đơn giản hóa bài toán và phù hợp với mục tiêu nghiên cứu, các phương tiện được quy ước và gom nhóm thành hai lớp chính, bao gồm xe hai bánh (đại diện cho xe máy, xe đạp,...) và xe bốn bánh (đại diện cho xe hơi, xe tải, xe buýt,...). Bên cạnh đó, do chất lượng hình ảnh thu thập từ camera giao thông còn hạn chế và các bước tiền xử lý không thể khắc phục hoàn toàn các yếu tố bất lợi như góc quay cao, góc quay xiên hoặc mật độ giao thông lớn, một số phương tiện đặc biệt là xe máy có thể bị che khuất hoặc chồng chéo, dẫn đến độ chính xác nhận diện suy giảm. Để khắc phục vấn đề này, khối xử lý còn tích hợp các thuật toán xử lý ảnh bổ sung như Polygon Fill, Rectangle Fill, Pixel-wise Logic và Non-zero Pixel Count nhằm tính toán tỷ lệ che phủ của xe máy trong các vùng quan tâm. Trên cơ sở đó, số lượng xe máy trong từng vùng được ước lượng, góp phần nâng cao độ chính xác tổng thể của quá trình đếm phương tiện.
    \item \textbf{Khối mô phỏng: } Sử dụng phần mềm SUMO để tái hiện mạng lưới giao thông thực tế. Khối này tiếp nhận hạ tầng từ OSM và luồng phương tiện từ khối dự báo để thực hiện các kịch bản mô phỏng giao thông vi mô, phục vụ việc đánh giá chiến lược điều phối.
    \item \textbf{Khối dự báo lưu lượng và điều chỉnh tín hiệu đèn giao thông: } Khối này chịu trách nhiệm dự báo lưu lượng giao thông trong tương lai dựa trên dữ liệu lịch sử từ khối nhận diện. Dữ liệu đếm phương tiện được chuyển đổi thành chuỗi thời gian và đưa vào mô hình LSTM (Long Short-Term Memory) để học các quy luật biến thiên của luồng giao thông. Trên cơ sở kết quả dự báo, khối này tính toán các thông số điều khiển tín hiệu tối ưu và gửi lệnh thông qua giao diện TraCI (Traffic Control Interface) để điều chỉnh chương trình đèn giao thông trong mô phỏng SUMO, nhằm tối ưu hóa khả năng thông hành của mạng lưới giao thông.
    \item \textbf{Khối hiển thị và đánh giá kết quả: } Cung cấp giao diện đồ họa (Dashboard) để người dùng theo dõi trạng thái giao thông thời gian thực, quản lý các kịch bản mô phỏng thông qua Scenario Explorer và xuất ra các biểu đồ đánh giá hiệu quả (Waiting Time, Mean Speed).
\end{itemize}

\subsection{Thiết kế khối thu thập dữ liệu}
Khối thu thập dữ liệu đảm nhiện việc tự động truy suất và tải về các hình ảnh snapshot từ website camera giao thông công khai của thành phố Hồ Chí Minh (giaothong.hochiminhcity.gov.vn), sau đó đẩy dữ liệu thu thập được lên khối lưu trữ đám mây Google Drive để phục vụ cho các bước xử lý tiếp theo.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.9\textheight, keepaspectratio]{fig/upload_raw_images.png}
    \caption[Lưu đồ chính cho quá trình thu thập dữ liệu]{Lưu đồ chính quá trình thu thập dữ liệu}
    \label{fig:upload_raw_images}
\end{figure}

Giải thích lưu đồ thu thập dữ liệu ở hình \ref{fig:upload_raw_images}: \\
\hspace*{1cm} Quá trình thu thập dữ liệu bắt đầu bằng việc khởi tạo Google Drive API để kết nối và thao tác với hệ thống lữu trữ đám mây. Tiếp theo, hệ thống sẽ khởi tạo một hàng đợi (drive\_queue) dùng để làm queue trung gian để giao tiếp giữa các tiến trình và một bộ nhớ đệm để lưu trữ mã SHA của ảnh được lưu gần nhất của mỗi camera. Sau đó, hệ thống sẽ tiến hành chạy đa luồng để thực hiện các tác vụ sau:
\begin{itemize}
    \item \textbf{Nhóm luồng truy suất camera: } Ở nhóm luồng này tùy theo số lượng camera cần giám sát là 13 camera ứng với 13 địa điểm mà hệ thống sẽ khởi tạo tương ứng số luồng. Mỗi luồng sẽ chịu trách nhiệm truy suất ảnh từ một camera cụ thể. Sau đó, cứ mỗi khoảng thời gian nhất định là khoảng 5 phút thì ảnh sẽ được gom lại và gửi vào hàng đợi drive\_queue để chờ được tải lên Google Drive.
    \item \textbf{Luồng chính: } Luồng này khởi tạo 2 nhóm luồng truy suất camera và nhóm luồng upload dữ liệu lên Drive. Ngoài ra, luồng này có đóng vai trò như một bộ điều phối, chịu trách nhiệm phân loại và giao task cho nhóm luồng upload ảnh lên Google Drive.
    \item \textbf{Nhóm luồng upload dữ liệu lên Drive: } Nhóm luồng này bao gồm 2 luồng chạy song song, chịu trách nhiệm nhận task để đẩy ảnh từ hàng đợi lên Google Drive.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/main_threading.png}
    \caption[Lưu đồ chi tiết hoạt động của luồng chính]{Lưu đồ chi tiết hoạt động của luồng chính}
    \label{fig:main_threading}
\end{figure}

Giải thích lưu đồ chi tiết hoạt động của luồng chính ở hình \ref{fig:main_threading}: \\
\hspace*{1cm} Lưu đồ này mô tả quy trình xử lý của một hệ thống giám sát đa luồng. Quá trình bắt đầu với việc khởi tạo hai nhóm luồng riêng biệt: một nhóm chịu trách nhiệm truy suất dữ liệu từ camera và một nhóm chuyên trách việc tải dữ liệu (upload), đi kèm với cơ chế đồng bộ hóa. Sau khi khởi động xong, hệ thống bước vào vòng lặp chính để liên tục giám sát và xử lý các công việc trong hàng đợi drive\_queue.

Trong vòng lặp này, hệ thống kiểm tra xem có tác vụ nào đang chờ hay không. Nếu hàng đợi rỗng, nó sẽ tạm nghỉ 0.1 giây để giảm tải trước khi kiểm tra lại. Khi nhận được tác vụ, hệ thống phân loại nó theo hai hướng: Nếu là tác vụ tạo thư mục, chương trình sẽ kiểm tra xem thư mục camera đó đã tồn tại trên Google Drive chưa, và chỉ tạo mới nếu chưa có. Nếu là tác vụ upload ảnh, hệ thống sẽ chuẩn bị dữ liệu cần thiết rồi phân phối công việc đó cho nhóm luồng upload xử lý.

Quy trình tuần hoàn này diễn ra liên tục cho đến khi có sự can thiệp ngắt từ người dùng. Khi đó, hệ thống sẽ gửi tín hiệu dừng đến tất cả các luồng, chờ đợi chúng hoàn thành nốt các công việc đang dang dở để đảm bảo an toàn dữ liệu, sau đó mới chính thức kết thúc chương trình.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio]{fig/camera_threading.png}
    \caption[Lưu đồ chi tiết hoạt động của nhóm luồng truy suất camera]{Lưu đồ chi tiết quá trình truy suất ảnh từ camera trên website}
    \label{fig:camera_threading}
\end{figure}

Giải thích lưu đồ chi tiết hoạt động của nhóm luồng truy suất camera ở hình \ref{fig:camera_threading}: \\
\hspace*{1cm} Luồng giám sát camera bắt đầu bằng việc khởi tạo batch buffer - một bộ đệm dùng để gom nhóm các ảnh trước khi upload - sau đó gửi một task thông qua drive\_queue để yêu cầu tạo folder cho camera trên Google Drive. Sau bước khởi tạo, hệ thống đi vào vòng lặp chính. Đầu tiên, hệ thống kiểm tra xem đang ở trạng thái hoạt động hay không. Nếu không hoạt động, hệ thống sẽ kiểm tra thời điểm hiện tại có nằm trong khung giờ cho phép hay không; nếu không thì ngủ 4 giây rồi quay lại đầu vòng lặp, nếu có thì chuyển sang trạng thái hoạt động. Khi đã ở trạng thái hoạt động, hệ thống gửi yêu cầu HTTP để lấy ảnh từ camera trên website giaothong.hochiminhcity.gov.vn.

Nếu việc lấy ảnh thất bại, hệ thống quay lại đầu vòng lặp để thử lại. Nếu thành công, hệ thống tính toán mã SHA của ảnh vừa lấy và so sánh với mã SHA của ảnh trước đó đã được lưu trong bộ nhớ đệm. Việc so sánh này nhằm phát hiện ảnh mới có thực sự khác biệt hay không, tránh lưu trữ các ảnh trùng lặp. Nếu mã SHA không thay đổi, nghĩa là ảnh giống ảnh cũ, hệ thống bỏ qua và quay lại vòng lặp. Nếu mã SHA khác nhau, hệ thống tiếp tục kiểm tra xem thời điểm ảnh được chụp có nằm trong khung giờ cho phép hay không. Nếu không nằm trong khung giờ, hệ thống chuyển về trạng thái không hoạt động và quay lại đầu vòng lặp.

Khi ảnh mới hợp lệ (SHA khác và trong khung giờ), hệ thống cập nhật mã SHA mới vào bộ nhớ đệm và thêm ảnh vào batch buffer. Tiếp theo, hệ thống kiểm tra xem batch buffer đã gom đủ ảnh trong khoảng thời gian 5 phút hay chưa. Nếu chưa đủ, hệ thống ngủ 4 giây rồi tiếp tục vòng lặp để lấy thêm ảnh. Nếu đã đủ, hệ thống đẩy toàn bộ ảnh trong batch qua drive\_queue để upload lên Google Drive, sau đó xóa batch buffer hiện tại và tiếp tục ngủ 4 giây trước khi bắt đầu chu kỳ mới. Vòng lặp này tiếp tục cho đến khi người dùng thực hiện ngắt (Ctrl+C), lúc đó hệ thống sẽ xóa batch buffer còn lại và kết thúc tiến trình.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.7\textheight, keepaspectratio]{fig/upload_threading.png}
    \caption[Lưu đồ chi tiết hoạt động của nhóm luồng upload dữ liệu lên Google Drive]{Lưu đồ chi tiết hoạt động của nhóm luồng upload dữ liệu lên Google Drive}
    \label{fig:upload_threading}
\end{figure}

Giải thích lưu đồ chi tiết hoạt động của nhóm luồng upload dữ liệu lên Google Drive ở hình \ref{fig:upload_threading}: \\
\hspace*{1cm} Luồng upload dữ liệu bắt đầu bằng việc thiết lập kết nối với Google Drive API để chuẩn bị cho quá trình tải lên. Sau khi kết nối thành công, hệ thống tiến hành kiểm tra sự tồn tại của thư mục địa điểm trên Google Drive; nếu thư mục chưa tồn tại, hệ thống sẽ tự động tạo mới thư mục này. Tiếp theo, trong thư mục địa điểm, hệ thống kiểm tra xem thư mục ngày (tương ứng với ngày hiện tại) đã có hay chưa, nếu chưa có thì tiến hành tạo thư mục ngày. Tương tự, bên trong thư mục ngày, hệ thống tiếp tục kiểm tra sự tồn tại của thư mục giờ và tạo mới nếu cần thiết. Cấu trúc thư mục phân cấp địa điểm/ngày/giờ này giúp tổ chức dữ liệu một cách có hệ thống và dễ dàng truy xuất. Sau khi đã đảm bảo cấu trúc thư mục hoàn chỉnh, luồng thực hiện upload batch hình ảnh lên Google Drive theo folder id tương ứng, hoàn tất quá trình tải lên và kết thúc


\subsection{Thiết kế khối lưu trữ}
Khối lưu trữ dữ liệu đóng vai trò tiếp nhận, tổ chức và quản lý toàn bộ dữ liệu trong hệ thống, bao gồm ảnh snapshot thu thập từ camera giao thông, dữ liệu sau tiền xử lý, kết quả nhận diện - đếm phương tiện, cũng như các tập dữ liệu đầu vào/đầu ra phục vụ mô phỏng và dự báo. Trong đề tài này, Google Drive được sử dụng như một nền tảng lưu trữ đám mây, đáp ứng yêu cầu về dung lượng, khả năng truy cập linh hoạt và thuận tiện cho việc chia sẻ, sao lưu dữ liệu trong quá trình nghiên cứu.

Việc sử dụng Google Drive cho phép hệ thống tách biệt hoàn toàn giữa khâu xử lý và khâu lưu trữ, từ đó giảm phụ thuộc vào hạ tầng máy chủ cục bộ và tăng tính linh hoạt trong quá trình mở rộng hoặc thay đổi môi trường triển khai. Khối lưu trữ không thực hiện các chức năng xử lý dữ liệu phức tạp mà chỉ đảm nhiệm vai trò lưu trữ tệp và cung cấp dữ liệu cho các khối xử lý tiếp theo thông qua các script truy xuất tự động.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.5\textheight, keepaspectratio]{fig/file_structure.png}
    \caption[Cấu trúc lưu trữ dữ liệu trên Google Drive]{Cấu trúc lưu trữ dữ liệu trên Google Drive}
    \label{fig:file_structure}
\end{figure}

Như trên hình \ref{fig:file_structure}, dữ liệu được tổ chức theo mô hình cây phân cấp, trong đó:
\begin{itemize}
    \item \textbf{DATN\_Image\_Traffic:} 
    Thư mục chủ đạo chứa dữ liệu đầu vào thô và dữ liệu đã qua xử lý, chia làm hai nhánh chính:
    
    \begin{itemize}
        \item \textbf{Raw Images:} 
        Dữ liệu đầu vào thu thập trực tiếp từ camera giao thông (giaothong.hochiminhcity.gov.vn). Cấu trúc gồm:
        \begin{itemize}
            \item \textbf{Location Folder:} Tên thư mục theo địa điểm thực tế (Ví dụ: \texttt{Nga\_Tu\_So}, \texttt{Cau\_Giay}).
            \item \textbf{Date Folder:} Phân loại theo ngày thu thập (Định dạng: \texttt{YYYY-MM-DD}).
            \item \textbf{Hour Folder:} Phân loại theo khung giờ (Ví dụ: \texttt{01h}, \texttt{02h}...).
            \item \textbf{[Unix\_Timestamp].jpg:} Các tệp ảnh gốc với tên là Unix Timestamp để đảm bảo tính duy nhất và tự động sắp xếp theo thời gian.
        \end{itemize}

        \item \textbf{Results:} 
        Lưu trữ kết quả sau khi xử lý/nhận diện, duy trì cấu trúc tương tự nhánh Raw Images để dễ dàng đối chiếu:
        \begin{itemize}
            \item \textbf{[Unix\_Timestamp].csv:} Tệp tin chứa nhãn (labels) hoặc metadata tương ứng với ảnh gốc.
            \item \textbf{[Hour].rar:} Tệp nén toàn bộ dữ liệu của khung giờ đó để tối ưu lưu trữ.
            \item \textbf{[YYYYMMDD\_HHmmss].jpg:} Ảnh kết quả (đã vẽ bounding box...) đặt tên theo định dạng thời gian truyền thống để người dùng dễ đọc bằng mắt thường.
        \end{itemize}
    \end{itemize}
\end{itemize}


\subsection{Thiết kế khối tiền xử lý ảnh}
Khối tiền xử lý ảnh có vai trò chuẩn hóa và nâng cao chất lượng đầu vào trước khi đưa vào khối nhận diện và phân tích phương tiện. Hệ thống thực hiện các bước tiền xử lý chính sau:
\begin{enumerate}
    \item \textbf{Tăng cường độ phân giải và chuẩn hóa kích thước ảnh: } Sử dụng Real-ESRGAN để nâng cao độ phân giải và giảm nhiễu cho các ảnh snapshot, ngoài ra còn tăng kích thước ảnh về chuẩn cố định nhằm đảm bảo tính nhất quán và cải thiện khả năng nhận diện của mô hình học sâu.
    \item \textbf{Chia đều ảnh thành các phần: }Ảnh sau khi được nâng cao chất lượng được chia thành bốn vùng con có kích thước bằng nhau. Việc chia nhỏ ảnh giúp mô hình tập trung tốt hơn vào các đặc trưng cục bộ, từ đó nâng cao độ chính xác trong việc phát hiện phương tiện, đặc biệt trong các tình huống mật độ giao thông cao hoặc khi các đối tượng bị che khuất một phần.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/upscale_image.png}
    \caption[Lưu đồ quá trình tiền xử lý ảnh]{Lưu đồ chi tiết quá trình tiền xử lý ảnh}
    \label{fig:upscale_image}
\end{figure}

Giải thích lưu đồ tiền xử lý ảnh ở hình \ref{fig:upscale_image}: \\
\hspace*{1cm} Ảnh đầu vào trước hết được đưa vào mô hình Real-ESRGAN đã được huấn luyện sẵn (pre-trained model) với các tham số cấu hình gồm hệ số phóng đại $scale=2$, mô hình \textit{RealESRGAN\_x2plus}, thiết bị xử lý \textit{cuda} và chế độ tính toán bán chính xác \textit{fp16}.

Sau khi quá trình nâng cao độ phân giải hoàn tất, chất lượng ảnh đầu ra được đánh giá thông qua việc tính toán giá trị độ sáng trung bình của các pixel trong ảnh. 
Nếu giá trị này nhỏ hơn một ngưỡng xác định (cụ thể là 5), ảnh được xem là không hợp lệ do quá tối và có khả năng phát sinh lỗi trong quá trình upscale. 
Trong trường hợp này, hệ thống tiến hành thực hiện lại bước nâng cao độ phân giải với cấu hình tương tự, nhưng chuyển sang chế độ tính toán toàn chính xác (\textit{fp32}) nhằm tăng độ ổn định và độ chính xác của kết quả.

Ngược lại, nếu ảnh đầu ra đạt yêu cầu về độ sáng, ảnh sẽ được chia thành bốn vùng con có kích thước bằng nhau. 
Quá trình này được thực hiện bằng cách xác định tọa độ trung điểm theo chiều rộng và chiều cao của ảnh, từ đó cắt ảnh thành bốn phần tương ứng với các góc \textit{Top-Left}, \textit{Top-Right}, \textit{Bottom-Left} và \textit{Bottom-Right}.

Cuối cùng, các ảnh con sau khi chia không được lưu dưới dạng các tệp ảnh riêng lẻ, mà được lưu trữ dưới dạng các giá trị trong bộ nhớ cùng với các id để nhận biết được các phần ảnh để phục vụ cho quá trình nhận diện và phân tích phương tiện ở khối tiếp theo.

\subsection{Thiết kế khối nhận diện và phân tích phương tiện}
Khối nhận diện và phân tích phương tiện sử dụng mô hình học sâu YOLOv11 đã được huấn luyện trước trên dataset COCO (pre-trained model) để phát hiện và phân loại các phương tiện giao thông trong từng ảnh snapshot. Tuy nhiên, bởi vì dữ liệu đầu vào có chất lượng không tốt, góc quay không tối ưu và mật độ giao thông cao, việc nhận diện chính xác các phương tiện, đặc biệt là xe máy trở nên khó khăn. Do đó, ngoài việc sử dụng mô hình YOLOv11 để phát hiện và phân loại phương tiện thì cần có thêm các bước xử lý ảnh bổ sung nhằm nâng nâng cao độ chính xác trong việc đếm xe máy, tính toán tỷ lệ che phủ của xe máy trong các vùng quan tâm (ROI - Region of Interest).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/vehicle_detector.png}
    \caption[Lưu đồ quá trình nhận diện và đếm phương tiện]{Lưu đồ quá trình nhận diện và đếm phương tiện}
    \label{fig:vehicle_detector}
\end{figure}

Giải thích lưu đồ nhận diện và đếm phương tiện ở hình \ref{fig:vehicle_detector}: \\
\hspace*{1cm} Khối này bắt đầu bằng việc tiếp nhận chính xác bốn ảnh con đã được tiền xử lý từ khối trước và tiến hành xử lý lần lượt từng ảnh. Trước hết, hệ thống kiểm tra xem ảnh con đầu vào có thuộc danh sách các Tile ID được cấu hình phân vùng ROI (Region of Interest) hay không. Nếu ảnh không nằm trong danh sách này, ảnh sẽ được đưa trực tiếp vào mô hình YOLOv11 để thực hiện phát hiện và phân loại các phương tiện, bao gồm xe hai bánh và xe bốn bánh. Ngược lại, nếu ảnh con thuộc một Tile ID có cấu hình phân vùng ROI, ảnh sẽ được xử lý bổ sung bằng các thuật toán xử lý ảnh nhằm ước lượng số lượng xe máy trong vùng quan tâm, đồng thời vẫn thực hiện nhận diện phương tiện bằng mô hình YOLOv11.
Sau khi hoàn tất quá trình xử lý đối với cả bốn ảnh con, các kết quả đếm phương tiện theo từng phần ảnh được tổng hợp lại.
Hệ thống tiếp tục kiểm tra sự trùng lặp của các phương tiện xuất hiện tại vùng rìa giữa các ảnh con và loại bỏ các trường hợp bị đếm trùng. Cuối cùng, kết quả tổng hợp được lưu trữ dưới dạng tệp csv. Đồng thời, các ảnh con được ghép lại để tạo thành ảnh kết quả, trong đó các phương tiện được phát hiện được biểu diễn bằng các bounding box, kèm theo phần che phủ của xe máy trong các vùng phân đoạn (nếu có).

Đối với việc chọn vùng quan tâm (ROI) để ước lượng số lượng xe máy thì trong đề tài này chỉ lựa chọn các vùng có mật độ xe máy cao và thường bị che khuất trong ảnh snapshot gốc. Các vùng phân đoạn được xác định thông qua một công cụ hỗ trợ được xây dựng riêng bằng Python. Công cụ này cho phép người vận hành khoanh vùng các khu vực cần khai thác trên ảnh,sau đó xuất ra tọa độ các điểm biên của vùng ROI theo hệ tọa độ pixel của ảnh. Các tọa độ ROI được biểu diễn dưới dạng các cặp điểm $(x, y)$ trong hệ tọa độ ảnh, tuân theo quy ước của thư viện OpenCV, với gốc tọa độ nằm tại góc trên bên trái ảnh. Những thông tin này được lưu trữ trong tệp cấu hình YAML tương ứng với từng địa điểm và được hệ thống sử dụng trong quá trình xử lý và phân tích ảnh như hình \ref{fig:segment_config}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/segment_config.png}
    \caption[Cấu trúc file YAML cấu hình vùng quan tâm (ROI)]{Cấu trúc file YAML cấu hình vùng quan tâm (ROI)}
    \label{fig:segment_config}
\end{figure}

Ngoài ra đối với các vùng có vật cản hoặc có yếu tố gây nhiễu trong vùng segment như bóng cây, biển quảng cáo, cột đèn... thì trong đề tài này còn cấu hình thêm các ROI để loại bỏ các yếu tố nhiễu này nhằm tránh ảnh hưởng đến kết quả đếm phương tiện như \textit{exclusion\_zones} trên hình \ref{fig:segment_config}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/process_quadrant_1.png}
    \caption[Lưu đồ xử lý từng ảnh con]{Lưu đồ xử lý từng ảnh con}
    \label{fig:process_quadrant}
\end{figure}

Giải thích lưu đồ xử lý từng ảnh con ở hình \ref{fig:process_quadrant}: \\
\hspace*{1cm}Trước hết, hệ thống nạp cấu hình phân vùng ROI (Region of Interest) từ tệp YAML đã được trình bày ở phần trước. Tiếp theo, mỗi ảnh con đầu vào được kiểm tra xem ID của phần ảnh đó có nằm trong danh sách các vùng được cấu hình ROI hay không.

Trong trường hợp ảnh con không thuộc danh sách ROI, ảnh sẽ được đưa trực tiếp vào mô hình YOLOv11 để thực hiện phát hiện và phân loại phương tiện. Ngược lại, nếu ảnh con thuộc vùng có cấu hình ROI, các tham số tương ứng như ngưỡng tin cậy (confidence threshold), ngưỡng IOU và tọa độ vùng quan tâm sẽ được trích xuất từ cấu hình để phục vụ cho các bước xử lý tiếp theo.

Tại giai đoạn này, mô hình YOLOv11 chỉ được sử dụng để phát hiện phương tiện bốn bánh. Đối với phương tiện hai bánh, hệ thống không áp dụng trực tiếp phương pháp phát hiện dựa trên bounding box do đặc thù kích thước nhỏ, mật độ cao và hiện tượng che khuất phổ biến, dẫn đến độ chính xác thấp, số lượng phát hiện không ổn định và kết quả trực quan không phản ánh đúng mật độ thực tế trong vùng quan tâm.

Thay vào đó, số lượng xe hai bánh được ước lượng gián tiếp thông qua tỷ lệ che phủ trong vùng ROI. Cụ thể, hệ thống áp dụng một số kỹ thuật xử lý ảnh bao gồm: Polygon Fill, Rectangle Fill, các phép toán logic theo pixel và đếm số pixel khác không (Non-zero Pixel Count) nhằm xác định tỷ lệ diện tích bị che phủ bởi xe máy trong vùng quan tâm. Trên cơ sở tỷ lệ che phủ này, số lượng xe hai bánh được ước lượng tương ứng.

Cuối cùng, kết quả đếm phương tiện hai bánh và bốn bánh, tỷ lệ che phủ của xe máy, cùng với ảnh trực quan hóa được lưu trữ trong bộ nhớ sẽ được tổng hợp và trả về cho khối xử lý chính của hệ thống.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/segment_detection.png}
    \caption[Lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI]{Lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI}
    \label{fig:segment_detection}
\end{figure}

Giải thích lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI ở hình \ref{fig:segment_detection}: \\
\hspace*{1cm}Trước hết, hệ thống tạo một mặt nạ nhị phân cho vùng ROI dạng đa giác dựa trên các tọa độ được trích xuất từ tệp cấu hình YAML, nhằm xác định khu vực cần phân tích trong ảnh. Tiếp theo, mô hình YOLOv11 được sử dụng để phát hiện các phương tiện trong ảnh, với các tham số ngưỡng tin cậy và ngưỡng IOU được cấu hình trước.

Sau khi thu được kết quả phát hiện, hệ thống lần lượt duyệt qua từng đối tượng và chỉ xem xét các phương tiện thuộc lớp xe bốn bánh. Đối với mỗi phương tiện hợp lệ về mặt lớp, hệ thống tính toán tọa độ bounding box và xác định xem tâm của bounding box có nằm trong vùng ROI hay không. Các phương tiện nằm ngoài vùng quan tâm sẽ không được đưa vào các bước xử lý tiếp theo.

Đối với các phương tiện bốn bánh có tâm bounding box nằm trong vùng ROI, hệ thống tiếp tục kiểm tra độ tin cậy của dự đoán. Những đối tượng có độ tin cậy nhỏ hơn ngưỡng cấu hình sẽ bị loại bỏ. Các phương tiện thỏa mãn đầy đủ các điều kiện trên sẽ được đưa vào danh sách phương tiện hợp lệ. Danh sách này sau đó được sắp xếp theo độ tin cậy giảm dần nhằm ưu tiên giữ lại các phát hiện có độ tin cậy cao trong quá trình xử lý trùng lặp.

Tiếp theo, hệ thống thực hiện loại bỏ các phát hiện trùng lặp dựa trên ngưỡng IOU đã được cấu hình. Trong trường hợp hai bounding box có giá trị IOU vượt quá ngưỡng cho phép, đối tượng có độ tin cậy thấp hơn sẽ bị loại bỏ khỏi danh sách.

Cuối cùng, số lượng phương tiện bốn bánh hợp lệ còn lại được cộng dồn vào biến đếm tổng. Đồng thời, thông tin vị trí của các bounding box này được lưu lại để phục vụ cho việc tính toán tỷ lệ che phủ của xe hai bánh cũng như trực quan hóa kết quả trong các bước xử lý tiếp theo.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/motorbike_coverage.png}
    \caption[Lưu đồ ước lượng số lượng xe máy trong vùng ROI]{Lưu đồ ước lượng số lượng xe máy trong vùng ROI}
    \label{fig:motorbike_coverage}
\end{figure}

Giải thích lưu đồ ước lượng số lượng xe máy trong vùng ROI ở hình \ref{fig:motorbike_coverage}: \\
\hspace*{1cm} Quy trình tính tỷ lệ che phủ của xe máy trên ảnh bắt đầu bằng việc thu thập vị trí các ô tô đã được phát hiện trong vùng quan tâm (ROI). Sau đó, hệ thống tạo mask cho vùng ROI dựa trên tọa độ các đỉnh đã được cấu hình sẵn, đồng thời tạo mask phân tích bằng cách loại trừ các vùng bị ô tô chiếm giữ ra khỏi mask ROI. Điều này đảm bảo rằng chỉ những vùng không có ô tô mới được đưa vào phân tích xe máy.

Tiếp theo, hệ thống kiểm tra diện tích vùng phân tích có lớn hơn 0 hay không. Nếu diện tích bằng 0 (tức là toàn bộ ROI đã bị ô tô che phủ hoặc ROI không hợp lệ), hệ thống sẽ gán tỷ lệ che phủ xe máy bằng 0\% và chuyển thẳng đến bước tạo ảnh trực quan hóa. Ngược lại, nếu diện tích lớn hơn 0, quy trình sẽ tiếp tục với các bước phát hiện xe máy.

Trong giai đoạn phát hiện xe máy, hệ thống áp dụng mask phân tích lên ảnh gốc và chuyển đổi sang không gian màu HSV để dễ dàng nhận diện màu sắc. Sau đó, hai phương pháp phát hiện được thực hiện song song: phát hiện các vùng có màu sắc đặc trưng của xe máy (như màu đen, xám của yên xe, khung xe) và phát hiện các cạnh đặc trưng như bánh xe, khung xe. Kết quả từ hai phương pháp này được kết hợp lại để tạo ra mask tổng hợp thể hiện vùng ước lượng là xe máy.

Trước khi tính toán diện tích, hệ thống kiểm tra xem có vùng loại trừ từ cấu hình hay không (ví dụ: vùng vỉa hè, cột đèn, hoặc các đối tượng cố định khác). Nếu có, các vùng này sẽ được loại bỏ khỏi kết quả phát hiện xe máy để đảm bảo độ chính xác.

Cuối cùng, hệ thống đếm số pixel trong vùng ước lượng là xe máy và tính tỷ lệ che phủ theo công thức: (Diện tích xe hai bánh / Diện tích ROI) x 100\%. Kết quả được trực quan hóa trên ảnh đầu ra với đường viền vùng ROI, vùng xe máy được tô màu đỏ, và thông tin tỷ lệ che phủ được hiển thị trực tiếp trên ảnh.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth,height=0.6\textheight,keepaspectratio]{fig/result_static_config.png}
    \caption[Cấu hình quy đổi diện tích che phủ sang số lượng xe hai bánh]{Cấu hình quy đổi diện tích che phủ sang số lượng xe hai bánh}
    \label{fig:result_static_config}
\end{figure}

Như hình \ref{fig:result_static_config}, hệ thống sử dụng hệ số quy đổi từ tỷ lệ che phủ sang số lượng xe hai bánh được cấu hình trong tệp YAML để ước lượng số lượng xe hai bánh trong vùng ROI. Hệ số này được xác định dựa trên việc tính toán phần trăm che phủ trung bình của một xe hai bánh trong vùng quan tâm, từ đó suy ra số lượng xe hai bánh tương ứng với tỷ lệ che phủ đo được. Kết quả khi quy đổi ra sẽ được cộng vào số lượng xe hai bánh của thời điểm đó và lưu trữ cùng với số lượng xe ô tô đã được phát hiện bởi mô hình YOLOv11.

Bước cuối cùng nhưng cũng không kém phần quan trọng, hệ thống sẽ tổng hợp các khung thời điểm về mỗi 5 phút để tạo thành chuỗi thời gian lưu lượng giao thông đồng nhất. Quá trình này bao gồm việc nhóm các bản ghi theo khoảng thời gian 5 phút, sau đó tính lượng trung bình phương tiện có trong khoảng thời gian đó. 

\subsection{Thiết kế khối mô phỏng giao thông (SUMO)}
Khối mô phỏng được thiết kế dựa trên một quy trình tự động hóa (Pipeline) tích hợp giữa dữ liệu địa không gian thực tế và các công cụ mô phỏng vi mô. Quy trình xây dựng môi trường mô phỏng bao gồm 5 giai đoạn chính:

\begin{enumerate}
    \item \textbf{Lựa chọn vùng (Location Selection):} Người dùng xác định khu vực nghiên cứu thông qua việc vẽ đa giác (Polygon) trên bản đồ tương tác. Tọa độ của đa giác này là dữ liệu đầu vào để truy xuất hạ tầng từ OpenStreetMap.
    \item \textbf{Xử lý dữ liệu OSM (OSM Processing):} Hệ thống sử dụng thư viện OSMnx để tải dữ liệu mạng lưới đường bộ. Tại giai đoạn này, một bước quan trọng là làm sạch dữ liệu (Network Cleanup) bằng cách loại bỏ các đoạn đường không phục vụ mô phỏng chính như đường hẻm nhỏ, đường cụt hoặc lối đi bộ để giảm tải tính toán (như hình \ref{fig:fig_I3_network_cleanup}).
    \item \textbf{Biên dịch mạng lưới (Network Compilation):} Dữ liệu OSM được công cụ \textit{netconvert} của SUMO biên dịch sang định dạng \texttt{.net.xml}. Giai đoạn này cũng thực hiện việc gộp các nút giao gần nhau và cấu hình hệ thống đèn tín hiệu mặc định.
    \item \textbf{Tạo luồng phương tiện (Flow Generation):} Hệ thống xác định các cạnh biên (\textit{fringe edges}) của mạng lưới để làm điểm phát sinh và điểm kết thúc của phương tiện. Luồng xe được tạo ra dựa trên tỷ lệ phân bổ phương tiện (xe máy, xe hơi) thu thập từ thực tế.
    \item \textbf{Cấu hình mô phỏng (SUMO Config):} Tổng hợp tất cả các tệp hạ tầng, lộ trình và tín hiệu vào một tệp cấu hình duy nhất (\texttt{.sumocfg}) để khởi chạy môi trường mô phỏng.
\end{enumerate}

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/fig_I3_network_cleanup.png}
        \caption[Xử lý làm sạch mạng lưới]{Xóa đường hẻm, cụt để giảm tải mô phỏng}
        \label{fig:fig_I3_network_cleanup}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/fig_I4_osm_export_sumo.png}
        \caption[Quy trình biên dịch mạng lưới]{Xuất dữ liệu OSM và biên dịch sang SUMO}
        \label{fig:fig_I4_osm_export_sumo}
    \end{minipage}
\end{figure}

Hình \ref{fig:fig_I3_network_cleanup} và \ref{fig:fig_I4_osm_export_sumo} minh họa giao diện của công cụ "SUMO Map Editor" được phát triển trong đề tài. Công cụ này cho phép người dùng tùy chỉnh bản đồ trước khi xuất sang định dạng SUMO thông qua các chức năng:
\begin{itemize}
    \item \textbf{Lọc và làm sạch đường:} Người dùng có thể xóa các loại đường không cần thiết (hẻm, đường cụt, đường nội bộ) bằng cách chọn loại đường trong danh sách bên trái hoặc xóa thủ công trên bản đồ để giảm tải cho mô phỏng.
    \item \textbf{Cấu hình xuất dữ liệu:} Tùy chỉnh các tham số chuyển đổi như gộp các nút giao gần nhau (junction grouping), tự động thêm đèn tín hiệu (TLS) và tạo luồng phương tiện ngẫu nhiên (random flows) để kiểm thử nhanh mạng lưới.
\end{itemize}

\subsection{Thiết kế khối dự báo lưu lượng và điều chỉnh tín hiệu đèn giao thông}

\subsubsection{Giới thiệu khối dự báo}

Khối dự báo lưu lượng giao thông chịu trách nhiệm dự báo mức độ tắc nghẽn trong tương lai dựa trên dữ liệu lịch sử từ khối nhận diện phương tiện. Kết quả dự báo được sử dụng để điều chỉnh tín hiệu đèn giao thông thông qua giao diện TraCI, nhằm tối ưu hóa khả năng thông hành của mạng lưới.

\subsubsection{Dữ liệu đầu vào từ mô phỏng SUMO}
Dữ liệu được thu thập từ SUMO thông qua TraCI API với các thông tin chính:
\begin{itemize}
    \item \textbf{Số lượng phương tiện:} Từ `traci.edge.getLastStepVehicleNumber(edge)` cho từng đoạn đường
    \item \textbf{Tốc độ trung bình:} Từ `traci.edge.getLastStepMeanSpeed(edge)` chuyển đổi sang km/h
    \item \textbf{Khoảng cách lấy mẫu:} 60 giây/lần để phù hợp với cửa sổ kiểm tra tính liên tục
    \item \textbf{Tập dữ liệu:} Khoảng 1000-1800 hàng từ 10 lần chạy × 2 giờ mô phỏng
    \item \textbf{Các đặc trưng:} 6 cột (5 cụm + nhãn tắc nghẽn toàn diện)
\end{itemize}

\subsubsection{Phát hiện Tắc Nghẽn Toàn Diện và Gán Nhãn}

Quy trình phát hiện tắc nghẽn giao thông được tham khảo từ nghiên cứu \cite{EiEiMon2020Gridlock}, bao gồm 5 bước chính:

\begin{enumerate}
    \item \textbf{Xác định Tốc Độ Thấp (Ngưỡng Động):} 
          Kiểm tra tốc độ trung bình của mỗi đoạn đường. Nếu $v_{mean} \leq 0.4 \times v_{max,vtype}$ 
          thì coi là tốc độ thấp. Ngưỡng được tính động dựa trên loại xe (vtype), 
          ví dụ: $v_{max} = 45$ km/h $\Rightarrow$ ngưỡng = 18 km/h.
    
    \item \textbf{Kiểm tra Tính Liên Tục (5 phút):} 
          Kiểm tra xem tốc độ thấp có kéo dài liên tục $\geq 5$ phút hay không. 
          Số bước kiểm tra (PERSISTENT\_STEPS) = 5 bước, mỗi bước 60 giây $\Rightarrow$ tổng 300 giây.
          
          Tính liên tục được coi là 1 nếu tất cả 5 bước trong lịch sử đều là tốc độ thấp.
    
    \item \textbf{Kiểm tra Cặp Upstream-Downstream:} 
          Một cặp (upstream, downstream) được coi là "cặp bị tắc" khi 
          cả hai đoạn đều có tốc độ thấp kéo dài (có tính liên tục).
          
          Điều kiện: $\text{upstream\_liên\_tục} = 1$ và $\text{downstream\_liên\_tục} = 1$
    
    \item \textbf{Phát hiện Tắc Nghẽn Cụm:} 
          Cụm được coi là bị tắc nếu có $\geq 1$ cặp thỏa điều kiện trên.
    
    \item \textbf{Tính Mức Độ Tắc Toàn Diện:}
          Mức độ tắc toàn diện (0-5) được tính dựa trên số cụm bị tắc:
          \begin{itemize}
              \item 0 cụm → mức độ = 0 (bình thường)
              \item 1 cụm → mức độ = 1
              \item 2 cụm → mức độ = 2
              \item 3 cụm → mức độ = 3
              \item 4 cụm → mức độ = 4
              \item 5 cụm → mức độ = 5 (toàn mạng tắc)
          \end{itemize}
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.75\textheight, keepaspectratio]{fig/fig_3_7_gridlock_detection_5steps.png}
    \caption[Lưu đồ quy trình phát hiện tắc toàn diện]{Lưu đồ chi tiết 5 bước phát hiện tắc toàn diện giao thông}
    \label{fig:gridlock_detection_5steps}
\end{figure}

Giải thích lưu đồ ở hình \ref{fig:gridlock_detection_5steps}: Quá trình phát hiện bắt đầu từ việc kiểm tra tốc độ trung bình của mỗi đoạn đường. Nếu tốc độ thấp hơn ngưỡng động (18 km/h), dữ liệu được lưu vào lịch sử. Tiếp theo, hệ thống kiểm tra xem tốc độ thấp có kéo dài liên tục trong 5 bước thời gian hay không. Khi cả hai điều kiện thỏa mãn, cặp upstream-downstream được coi là có tính liên tục. Nếu ít nhất 1 cặp trong cụm đạt điều kiện này, cụm được gắn nhãn là bị tắc. Cuối cùng, mức độ tắc toàn diện được tính dựa trên số cụm bị tắc.

\subsubsection{Tiền Xử Lý Dữ Liệu}

\paragraph{Chuẩn Hóa (Bình Thường Hóa):}
Sử dụng MinMaxScaler để chuẩn hóa dữ liệu vào khoảng [0, 1]:
$$x_{\text{chuẩn\_hóa}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}$$

Lý do: LSTM hoạt động tốt nhất với giá trị nhỏ, tránh hiện tượng gradient biến mất hoặc bùng nổ.

\paragraph{Cửa Sổ Trượt (Chuỗi Thời Gian):}
Dữ liệu được biến đổi từ dạng tuần tự sang dạng học có giám sát:
\begin{itemize}
    \item \textbf{Cửa sổ Lookback:} 10 bước thời gian = 10 phút = 600 giây
    \item \textbf{Phép biến đổi:} $[X(t-10), X(t-9), \ldots, X(t-1)] \rightarrow y(t)$
    \item \textbf{Hình dạng dữ liệu:} $[\text{số mẫu}, 10 \text{ bước}, 6 \text{ đặc trưng}]$
    \item \textbf{Tại sao 10 phút:} Khớp với thời gian kiểm tra tính liên tục, 
          tương ứng 5-10 chu kỳ đèn giao thông, cân bằng giữa thông tin lịch sử dài và tránh quá khớp
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.6\textheight, keepaspectratio]{fig/fig_3_7_sliding_window.png}
    \caption[Minh họa kỹ thuật cửa sổ trượt cho chuỗi thời gian]{Minh họa phương pháp cửa sổ trượt với Lookback = 10 bước để tạo dữ liệu huấn luyện}
    \label{fig:sliding_window}
\end{figure}

\subsubsection{Kiến Trúc Mô Hình LSTM}

\paragraph{Cấu Trúc Mạng:}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Tầng} & \textbf{Loại} & \textbf{Hình Dạng Đầu Ra} \\
\hline
1 & LSTM(64, return\_sequences=True) & (batch, 10, 64) \\
2 & Bỏ Bớt(0,2) & (batch, 10, 64) \\
3 & LSTM(32) & (batch, 32) \\
4 & Bỏ Bớt(0,2) & (batch, 32) \\
5 & Kết Nối Đầy Đủ(1) & (batch, 1) \\
\hline
\end{tabular}
\end{table}

\paragraph{Giải Thích Kiến Trúc:}
\begin{itemize}
    \item \textbf{Tầng 1 (LSTM 64 neuron):} Học các mẫu phức tạp từ 60 đặc trưng đầu vào
    \item \textbf{Bỏ Bớt (0,2):} Ngẫu nhiên tắt 20\% neuron, ngăn chặn quá khớp với tập dữ liệu nhỏ
    \item \textbf{Tầng 3 (LSTM 32 neuron):} Nén thông tin thành biểu diễn 32 chiều
    \item \textbf{Kết Nối Đầy Đủ (1 neuron):} Ánh xạ từ biểu diễn thành 1 đầu ra (dự báo tắc toàn diện)
\end{itemize}

\paragraph{Ba Cổng LSTM:}
Mỗi ô LSTM có ba cổng điều khiển dòng thông tin:
\begin{align}
\text{Cổng Quên:} \quad f_t &= \sigma(W_f[\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_f) \\
\text{Cổng Đầu Vào:} \quad i_t &= \sigma(W_i[\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_i) \\
\text{Trạng Thái Ô:} \quad C_t &= f_t \odot C_{t-1} + i_t \odot \tilde{C}_t \\
\text{Cổng Đầu Ra:} \quad o_t &= \sigma(W_o[\mathbf{h}_{t-1}, \mathbf{x}_t] + \mathbf{b}_o) \\
\text{Trạng Thái Ẩn:} \quad \mathbf{h}_t &= o_t \odot \tanh(C_t)
\end{align}

Ứng dụng: Cổng Quên quên thông tin cũ không còn thích hợp, Cổng Đầu Vào nhớ sự kiện tắc nghẽn mới $\rightarrow$ Dự báo tắc toàn diện tốt hơn.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.7\textheight, keepaspectratio]{fig/fig_3_7_lstm_architecture.png}
    \caption[Kiến trúc mô hình LSTM dự báo]{Sơ đồ kiến trúc mô hình LSTM gồm 5 tầng: Input, 2 tầng LSTM (64 & 32 neuron), 2 tầng Dropout, và 1 tầng Dense Output}
    \label{fig:lstm_architecture}
\end{figure}

\subsubsection{Cấu Hình Huấn Luyện}

\begin{itemize}
    \item \textbf{Bộ Tối Ưu:} Adam - Điều chỉnh tốc độ học thích ứng, kết hợp động lượng với RMSprop
    \item \textbf{Hàm Mất Mát:} MSE (Sai số bình phương trung bình) - phù hợp cho bài toán hồi quy
    \item \textbf{Lần Lặp:} 200 lần để mô hình hội tụ
    \item \textbf{Kích Thước Lô:} 32 mẫu/lô để cân bằng tốc độ huấn luyện và tính ổn định
    \item \textbf{Tỷ Lệ Bỏ Bớt:} 0,2 (bỏ 20\% neuron) - tiêu chuẩn cho LSTM với tập dữ liệu nhỏ
    \item \textbf{Chia Kiểm Tra:} 20\% dữ liệu dùng làm xác thực trong quá trình huấn luyện
\end{itemize}

\textbf{Đặc điểm bộ tối ưu Adam:}
\begin{itemize}
    \item Tự động điều chỉnh tốc độ học cho từng tham số
    \item Không cần điều chỉnh tốc độ học thủ công
    \item Hoạt động đặc biệt tốt với LSTM và chuỗi thời gian
\end{itemize}

\subsubsection{Tích Hợp Dự Báo vào Mô Phỏng SUMO}

Sau khi mô hình được huấn luyện, kết quả dự báo được sử dụng để điều chỉnh tín hiệu đèn trong SUMO thông qua TraCI:
\begin{itemize}
    \item Dự báo mức độ tắc toàn diện tại thời điểm t+1
    \item So sánh với ngưỡng cảnh báo để quyết định tăng/giảm thời lượng pha xanh
    \item Gửi lệnh TraCI: `traci.trafficlight.setPhase(tlsID, phaseID)`
    \item Cập nhật lệnh cứ mỗi 60 giây (khoảng cách lấy mẫu)
\end{itemize}


\subsubsection{Các agent điều khiển giao thông}

Hệ thống điều khiển giao thông thông minh được xây dựng theo kiến trúc phân cấp với hai agent độc lập chuyên biệt: DurationAgent dùng LSTM để dự báo thời lượng xanh của tín hiệu, và LaneRatioAgent sử dụng Policy Gradient với Beta Distribution để phân bổ tỷ lệ làn đường.

\paragraph{DurationAgent: Dự báo Thời Lượng Xanh}

DurationAgent được triển khai dựa trên mô hình LSTM (Long Short-Term Memory) như được trình bày trong Chương 2, Mục 2.1.1. Mục đích của agent này là dự báo thời lượng xanh tối ưu cho từng pha tín hiệu giao thông.

\textbf{Kiến trúc mạng:}

DurationAgent bao gồm các thành phần chính:
\begin{itemize}
    \item \textbf{Lớp LSTM}: Một lớp LSTM với 64 units ẩn để xử lý chuỗi thời gian dữ liệu giao thông, cho phép agent ghi nhớ các mẫu lưu lượng dài hạn.
    \item \textbf{Lớp Linear}: Một lớp tuyến tính để chuyển đổi hidden state thành giá trị dự báo thời lượng xanh.
    \item \textbf{Hàm Kích Hoạt}: Sigmoid activation để đảm bảo output nằm trong khoảng $[0, 1]$, sau đó scale để có giá trị thực tế theo giây.
\end{itemize}

\textbf{Quá trình xử lý đầu vào:}

Tại mỗi time step $t$, DurationAgent nhận vào một vector đặc trưng 3 chiều:

\begin{equation}
x_t = [\text{flow}_t, \text{density}_t, \text{waiting\_time}_t]
\end{equation}

Trong đó:
\begin{itemize}
    \item $\text{flow}_t$: Lưu lượng xe qua detector E1 tại time step $t$ (vehicles/phút).
    \item $\text{density}_t$: Mật độ phương tiện được đo bằng phần trăm chiếm dụng của detector (0-100\%).
    \item $\text{waiting\_time}_t$: Thời gian chờ trung bình của các phương tiện (giây).
\end{itemize}

Dữ liệu được chuẩn hóa về $[0, 1]$ sử dụng min-max normalization để đảm bảo ổn định số học khi xử lý LSTM:

\begin{equation}
x_t^{\text{norm}} = \frac{x_t - x_{\min}}{x_{\max} - x_{\min}}
\end{equation}

\textbf{Quá trình xử lý LSTM:}

Tại mỗi time step, input $x_t^{\text{norm}}$ cùng với hidden state trước đó $h_{t-1}$ và cell state $c_{t-1}$ được đưa vào khối LSTM. Theo lý thuyết trong Chương 2, Mục 2.3.2, khối LSTM thực hiện quá trình với ba cổng điều khiển:

\begin{enumerate}
    \item \textbf{Cổng Quên}: $f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$ - Quyết định thông tin nào từ cell state trước được giữ lại để ghi nhớ các mẫu lưu lượng dài hạn.
    
    \item \textbf{Cổng Đầu Vào}: $i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)$ và $\tilde{c}_t = \tanh(W_c \cdot [h_{t-1}, x_t] + b_c)$ - Cập nhật thông tin mới về lưu lượng hiện tại vào cell state.
    
    \item \textbf{Cập Nhật Cell State}: $c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t$ - Kết hợp thông tin cũ (mẫu lịch sử) và thông tin mới (tình trạng hiện tại).
    
    \item \textbf{Cổng Đầu Ra}: $o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)$ - Lọc thông tin cần thiết từ cell state để sinh ra hidden state.
    
    \item \textbf{Hidden State}: $h_t = o_t \odot \tanh(c_t)$ - Đầu ra của khối LSTM chứa đặc trưng đã trích xuất.
\end{enumerate}

Cơ chế này cho phép LSTM tránh vấn đề vanishing/exploding gradient (Chương 2) và xử lý hiệu quả các chuỗi thời gian dài 3600 timesteps (1 giờ mô phỏng).

\textbf{Dự báo thời lượng xanh:}

Hidden state $h_t$ được đưa qua lớp Linear rồi Sigmoid activation:

\begin{equation}
\text{duration}_t = \sigma(W_{\text{out}} \cdot h_t + b_{\text{out}}) \times T_{\max}
\end{equation}

Trong đó:
\begin{itemize}
    \item $\sigma$ là hàm sigmoid đảm bảo output trong $[0, 1]$.
    \item $T_{\max}$ là thời gian xanh tối đa được phép (ví dụ: 80 giây).
    \item Kết quả là thời lượng xanh dự báo nằm trong khoảng $[0, T_{\max}]$ giây.
\end{itemize}

\textbf{Huấn luyện với Actor-Critic:}

DurationAgent được huấn luyện sử dụng Actor-Critic framework từ Reinforcement Learning (Chương 2, Mục 2.2):

\begin{itemize}
    \item \textbf{Actor}: Mạng LSTM + output layer sinh ra hành động (thời lượng xanh).
    \item \textbf{Critic}: Một mạng nơ-ron khác ước lượng giá trị của state $V(s)$.
\end{itemize}

Hàm loss được tính như sau:

\begin{equation}
\mathcal{L}_{\text{policy}} = -\mathbb{E}[\log \pi(a|s) \cdot A(s, a)]
\end{equation}

\begin{equation}
\mathcal{L}_{\text{value}} = \mathbb{E}[(V(s) - G_t)^2]
\end{equation}

\begin{equation}
\mathcal{L}_{\text{total}} = \alpha \cdot \mathcal{L}_{\text{policy}} + \beta \cdot \mathcal{L}_{\text{value}}
\end{equation}

Trong đó:
\begin{itemize}
    \item $A(s, a) = G_t - V(s)$ là Advantage (lợi thế) - đo mức độ tốt hơn của hành động so với giá trị trung bình.
    \item $G_t = \sum_{i=0}^{T-t} \gamma^i r_{t+i}$ là cumulative reward từ time step $t$.
    \item $\gamma = 0.99$ là discount factor.
    \item $\alpha = 1.0, \beta = 0.5$ là hệ số cân nặng giữa hai thành phần loss.
    \item Training sử dụng optimizer Adam với learning rate $lr = 10^{-4}$.
\end{itemize}

\paragraph{LaneRatioAgent: Phân Bổ Tỷ Lệ Làn Đường}

LaneRatioAgent sử dụng Policy Gradient với Beta Distribution (Chương 2, Mục 2.3) để sinh ra vector tỷ lệ phân bổ làn đường, cho phép agent linh hoạt điều chỉnh lưu lượng giữa các làn dựa trên tình trạng giao thông thực tế.

\textbf{Kiến trúc:}

LaneRatioAgent gồm:
\begin{itemize}
    \item \textbf{Policy Network}: Một mạng nơ-ron nhiều lớp (MLP) nhận state và sinh ra các tham số $\mu$ (mean) và $\sigma$ (standard deviation) của Beta Distribution.
    \item \textbf{Beta Distribution Parameterization}: Chuyển đổi $\mu$ và $\sigma$ thành các tham số hình dạng $\alpha$ và $\beta$ của Beta Distribution.
    \item \textbf{Action Sampling}: Sample hành động từ Beta Distribution và clamp về $[\epsilon, 1-\epsilon]$ để tránh các giá trị cực đoan.
\end{itemize}

\textbf{Quá trình tạo tỷ lệ làn:}

Từ state $s_t$ (trạng thái giao thông hiện tại), policy network sinh ra:

\begin{equation}
\mu, \sigma = \text{MLP}(s_t)
\end{equation}

Chuyển đổi thành tham số Beta Distribution:

\begin{equation}
\alpha_i = \mu_i \cdot \left(\frac{\mu_i(1-\mu_i)}{\sigma_i^2} - 1\right)
\end{equation}

\begin{equation}
\beta_i = (1-\mu_i) \cdot \left(\frac{\mu_i(1-\mu_i)}{\sigma_i^2} - 1\right)
\end{equation}

Sample hành động từ Beta Distribution cho mỗi làn $i$:

\begin{equation}
r_i \sim \text{Beta}(\alpha_i, \beta_i), \quad i = 1, 2, \ldots, N_{\text{lanes}}
\end{equation}

Chuẩn hóa tỷ lệ sao cho tổng bằng 1 (đảm bảo tính hợp lệ của phân bổ):

\begin{equation}
r_i^{\text{norm}} = \frac{r_i}{\sum_{j=1}^{N_{\text{lanes}}} r_j}
\end{equation}

\textbf{Ưu điểm của Beta Distribution:}

Theo Chương 2, Mục 2.3, Beta Distribution được chọn vì:
\begin{itemize}
    \item Hỗ trợ hành động liên tục trên $[0, 1]$, phù hợp cho bài toán phân bổ tỷ lệ.
    \item Linh hoạt: có thể biểu diễn nhiều dạng phân bố bằng cách điều chỉnh $\alpha$ và $\beta$.
    \item Phương sai của phân bố khuyến khích agent khám phá các tỷ lệ làn khác nhau (exploration).
\end{itemize}

\textbf{Huấn luyện:}

LaneRatioAgent được huấn luyện với:

\begin{equation}
\mathcal{L}_{\text{policy}} = -\mathbb{E}[\log p(r|s) \cdot A(s, r)]
\end{equation}

\begin{equation}
\mathcal{L}_{\text{entropy}} = -\beta_{\text{entropy}} \cdot \mathbb{E}[\text{entropy}(\text{Beta}(\alpha, \beta))]
\end{equation}

\begin{equation}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{policy}} + \mathcal{L}_{\text{value}} + \mathcal{L}_{\text{entropy}}
\end{equation}

Entropy loss (với $\beta_{\text{entropy}} = 0.01$) khuyến khích agent khám phá các tỷ lệ làn khác nhau, tránh bị mắc kẹt ở local optima và giúp tìm kiếm chiến lược tối ưu toàn cục.

\subsubsection{Tích hợp với SUMO qua TraCI}

\paragraph{Trích xuất State từ Sensors} \mbox{}\\

Hệ thống giao tiếp với SUMO simulation thông qua TraCI (Traffic Control Interface). Tại mỗi time step, dữ liệu trạng thái được trích xuất từ các E1 detectors (loop detectors) được cài đặt tại các làn đường:

\begin{equation}
\text{state}_t = [\text{flow}_t, \text{density}_t, \text{waiting\_time}_t]
\end{equation}

Dữ liệu được trích xuất mỗi $\Delta t = 1$ giây qua TraCI bằng các hàm:

\begin{itemize}
    \item \textbf{getLastStepVehicleNumber}: Trích xuất số lượng phương tiện qua detector trong time step vừa qua (đơn vị: vehicles).
    \item \textbf{getLastStepOccupancy}: Trích xuất tỷ lệ chiếm dụng của detector (đơn vị: \%).
    \item \textbf{getWaitingTime}: Trích xuất thời gian chờ trung bình trên cạnh đường (đơn vị: giây).
\end{itemize}

\paragraph{Áp dụng Action vào Tín Hiệu Đèn Giao Thông} \mbox{}\\

Kết quả dự báo từ các agent được chuyển đổi thành các lệnh điều khiển đèn giao thông thông qua giao diện TraCI:

\textbf{Từ DurationAgent:} Thời lượng xanh dự báo $d_t$ được áp dụng trực tiếp vào tín hiệu đèn giao thông để điều chỉnh thời lượng pha hiện tại.

\textbf{Từ LaneRatioAgent:} Tỷ lệ phân bổ $r_i^{\text{norm}}$ được sử dụng để ưu tiên các làn có lưu lượng cao (nếu SUMO hỗ trợ tính năng phân bổ làn động).

Cả hai hành động được gửi đến SUMO qua TraCI API để cập nhật trạng thái tín hiệu trong từng bước mô phỏng.

\paragraph{Hàm Reward} \mbox{}\\

Reward được tính từ các metric giao thông để đánh giá hiệu quả của các hành động:

\begin{equation}
\text{reward}_t = -\alpha \cdot \text{avg\_queue\_length}_t - \beta \cdot \text{avg\_waiting\_time}_t + \gamma \cdot \text{throughput}_t
\end{equation}

Với:
\begin{itemize}
    \item $\alpha = 1.0$: Hệ số để giảm độ dài hàng đợi (prioritize queue reduction).
    \item $\beta = 0.1$: Hệ số để giảm thời gian chờ (lower priority).
    \item $\gamma = 0.01$: Hệ số để tăng thông lượng (bonus cho nhiều xe qua).
    \item $\text{throughput}_t = \text{số xe qua giao lộ trong time step } t$.
\end{itemize}

Reward được thiết kế sao cho agent được thưởng khi giảm hàng đợi và thời gian chờ, đồng thời tối đa hóa số lượng xe có thể qua giao lộ.

\paragraph{Huấn luyện Parallel với 16 Workers} \mbox{}\\

Để tăng tốc độ training, hệ thống sử dụng multi-processing với 16 worker processes chạy song song:

\begin{itemize}
    \item \textbf{Mỗi worker}: Chạy một SUMO instance độc lập để thu thập dữ liệu (data collection).
    \item \textbf{Batch Update}: Sau mỗi 4 episodes (từ 4 workers), models được cập nhật trên GPU bằng batch gradient descent.
    \item \textbf{Synchronization}: Tham số model mới được broadcast đến tất cả workers để tiếp tục training.
    \item \textbf{Tốc độ}: Thay vì training tuần tự (1 episode/lần), parallel training cho phép 16 episodes cùng lúc, tăng tốc độ training khoảng 10-12x.
\end{itemize}
\subsection{Thiết kế khối hiển thị và đánh giá kết quả}
Khối hiển thị được thiết kế là một ứng dụng web dashboard, tích hợp các công cụ hỗ trợ người dùng phân tích kịch bản giao thông:
\begin{itemize}
    \item \textbf{Scenario Explorer:} Công cụ cho phép người dùng tùy chỉnh các tham số đầu vào của mô phỏng như lưu lượng xe, tỷ lệ phương tiện và cấu hình luồng. Người dùng có thể quan sát trực quan các tuyến đường (routes) di chuyển trong mạng lưới.
    \item \textbf{SUMO Control Interface:} Giao diện điều khiển thời gian thực kết nối với lõi mô phỏng qua TraCI. Giao diện này hiển thị các thông số vận hành của nút giao (trạng thái đèn, độ trễ) và cho phép can thiệp thủ công vào quá trình điều tiết nếu cần thiết.
    \item \textbf{Công cụ đánh giá:} Sau khi kết thúc mô phỏng, hệ thống tự động trích xuất dữ liệu từ các tệp \texttt{tripinfo.xml} và \texttt{summary.xml} để tính toán các chỉ số: thời gian di chuyển trung bình (Mean Travel Time), tốc độ trung bình (Mean Speed) và tổng lượng khí thải.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/fig_II4_scenario_explorer.png}
    \caption[Giao diện Scenario Explorer]{Giao diện Scenario Explorer giúp quản lý và tùy chỉnh kịch bản}
    \label{fig:fig_II4_scenario_explorer}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/fig_II4_sumo_control.png}
    \caption[Giao diện SUMO Control]{Giao diện điều khiển và giám sát quá trình mô phỏng thực tế}
    \label{fig:fig_II4_sumo_control}
\end{figure}

