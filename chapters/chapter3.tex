\chapter{THIẾT KẾ HỆ THỐNG}

\section{YÊU CẦU CỦA HỆ THỐNG}
Hệ thống được đề xuất hướng tới việc mô phỏng, dự báo và điều tiết giao thông dựa trên dữ liệu hình ảnh snapshot thu thập từ camera giao thông, kết hợp các kỹ thuật học sâu và mô phỏng giao thông vi mô. Để đáp ứng mục tiêu nghiên cứu và đảm bảo khả năng triển khai thực tế, hệ thống cần thỏa mãn các yêu cầu chức năng và phi chức năng sau.

Về giai đoạn thu thập dữ liệu, hệ thống cần đảm bảo các yêu cầu sau:
\begin{itemize}
    \item Tiếp nhận được dữ liệu hình ảnh giao thông dạng snapshot từ các camera giao thông đặt tại các nút giao.
    \item Các ảnh này phải được quản lý, lưu trữ và gắn nhãn thời gian rõ ràng.
\end{itemize}

Về giai đoạn tiền xử lý dữ liệu, nhận diện và đếm phương tiện, hệ thống cần đáp ứng các yêu cầu sau:
\begin{itemize}
    \item Các ảnh đầu vào cần được thực hiện các bước xử lý ảnh cơ bản như tăng độ phân giải, giảm nhiễu và chuẩn hóa kích thước.
    \item Hệ thống tích hợp mô hình YOLOv11 nhằm nhận diện các phương tiện giao thông chính trên từng ảnh snapshot, trong đó các phương tiện được quy ước và phân loại thành hai nhóm: xe hai bánh (xe máy) và xe bốn bánh (xe hơi).
    \item Kết quả phát hiện bao gồm số lượng phương tiện theo từng loại tại mỗi thời điểm và tại từng địa điểm giám sát cụ thể, trong đó “địa điểm” được hiểu là vị trí camera đại diện cho một khu vực giao thông trên bản đồ.
    \item Lưu trữ kết quả đếm phương tiện với timestamp và vị trí tương ứng để phục vụ cho các bước xử lý tiếp theo.
    \item Đảm bảo độ chính xác cao trong việc nhận diện và đếm phương tiện, với sai số không vượt quá $5\%$ so với thực tế.
\end{itemize}

Tiếp đến là yêu cầu về mô phỏng giao thông:
\begin{itemize}
    \item Khả năng xây dựng mạng lưới giao thông mô phỏng tương ứng với khu vực thực tế từ dữ liệu OpenStreetMap (OSM).
    \item Tái hiện luồng phương tiện (xe hai bánh và xe bốn bánh) với lưu lượng biến thiên theo thời gian dựa trên các giá trị thực tế và dự báo.
    \item Hỗ trợ lập trình điều khiển tín hiệu đèn giao thông thông qua giao diện TraCI của SUMO.
\end{itemize}

Đối với giai đoạn xây dựng chuỗi thời gian và dự báo lưu lượng giao thông, hệ thống cần thỏa mãn các yêu cầu sau:
\begin{itemize}
    \item None
\end{itemize}

Đối với giai đoạn tích hợp và điều khiển luồng giao thông, hệ thống cần đáp ứng các yêu cầu sau:
\begin{itemize}
    \item None
\end{itemize}

Cuối cùng, về giai đoạn trực quan hóa và phân tích, hệ thống cần:
\begin{itemize}
    \item Cung cấp giao diện trực quan để hiển thị kết quả nhận diện, đếm phương tiện, dự báo lưu lượng và mô phỏng giao thông.
    \item Hỗ trợ các biểu đồ, bản đồ nhiệt và các công cụ phân tích để người dùng có thể dễ dàng hiểu và đánh giá tình hình giao thông. 
     \item So sánh hiệu quẩ giữa việc xử dụng chiến lược điều tiết và không sử dụng để đánh giá hiệu quả của các biện pháp điều tiết dựa trên các chỉ số: thời gian di chuyển trung bình, thời gian đợi, chiều dài hàng đợi.
\end{itemize}

\section{KIẾN TRÚC HỆ THỐNG}
\subsection{Sơ đồ khối hệ thống}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.6\textheight, keepaspectratio]{fig/system_block_diagram.png}
    \caption{Sơ đồ khối kiến trúc hệ thống}
    \label{fig:system_block_diagram}
\end{figure}

\textbf{Chức năng từng khối: }
\begin{itemize}
    \item \textbf{Khối thu thập dữ liệu: } Khối thu thập dữ liệu chịu trách nhiệm tiếp nhận các hỉnh ảnh snapshot từ nguồn mở Open Street Map (OSM). Trong đề tài này, dữ liệu không được thu thập trực tiếp từ hệ thống camera vật lý mà được lấy từ nguồn dữ liệu mở, nơi các camera giao thông đã được thiết lập và công bố sẵn cho mục đích quan sát và tham khảo. Quá trình thu thập dữ liệu được thực hiện thông qua truy suất tự động (web scraping) để tải về các hình ảnh snapshot tại các thời điểm xác định (khoảng 12 giây một ảnh). 
    \item \textbf{Khối lưu trữ: } Khối lưu trữ đóng vai trò quản lý và tổ chức toàn bộ dữ liệu hình ảnh thu thập được cũng như các dữ liệu trung gian phát sinh trong quá trình xử lý. Các ảnh snapshot thu thập từ camera phía OSM được lưu trữ dưới dạng cấu trúc thư mục phân cấp trên hệ thống lưu trữ tệp tin đám mây Google Drive. Mỗi ảnh được gắn nhãn thời gian rõ ràng và sắp xếp theo từng thư mục tương ứng với địa điểm giám sát, nhằm đảm bảo tính nhất quán và thuận tiện cho việc truy xuất, xử lý và phân tích về sau. Bên cạnh đó, các ảnh kết quả sau khi nhận diện và đếm phương tiện, dữ liệu thống kê mật độ giao thông theo thời gian, cũng như dữ liệu đầu vào và đầu ra của mô hình LSTM đều được lưu trữ tập trung tại khối này.
    \item \textbf{Khối tiền xử lý ảnh: } Khối tiền xử lý ảnh đảm nhiệm việc thực hiện các phép biến đổi cần thiết nhằm cải thiện chất lượng dữ liệu hình ảnh trước khi đưa vào mô hình nhận diện. Nguyên nhân là do các ảnh snapshot thu thập từ camera giao thông công khai trên mạng thường có chất lượng không đồng đều, chịu ảnh hưởng bởi nhiều yếu tố như độ phân giải thấp, nhiễu ảnh, điều kiện ánh sáng không ổn định và góc chụp chưa tối ưu. Do đó, khối này áp dụng một số kỹ thuật xử lý ảnh cơ bản, bao gồm tăng cường độ phân giải (super-resolution), lọc nhiễu (denoising), chuẩn hóa kích thước ảnh (resizing) và chia nhỏ ảnh nhằm đảm bảo dữ liệu đầu vào cho mô hình nhận diện đạt chất lượng tốt hơn và có tính nhất quán, dễ dàng nhận diện.
    \item \textbf{Khối nhận diện và phân tích phương tiện: } Khối nhận diện và phân tích phương tiện sử dụng mô hình học sâu YOLOv11 để thực hiện phát hiện và phân loại các phương tiện giao thông xuất hiện trong từng ảnh snapshot. Mô hình được khởi tạo từ trọng số huấn luyện sẵn (pre-trained) trên các tập dữ liệu lớn và đa dạng, nhờ đó có khả năng nhận diện hiệu quả các loại phương tiện phổ biến. Tuy nhiên, nhằm đơn giản hóa bài toán và phù hợp với mục tiêu nghiên cứu, các phương tiện được quy ước và gom nhóm thành hai lớp chính, bao gồm xe hai bánh (đại diện cho xe máy) và xe bốn bánh (đại diện cho xe hơi). Bên cạnh đó, do chất lượng hình ảnh thu thập từ camera giao thông còn hạn chế và các bước tiền xử lý không thể khắc phục hoàn toàn các yếu tố bất lợi như góc quay cao, góc quay xiên hoặc mật độ giao thông lớn, một số phương tiện đặc biệt là xe máy có thể bị che khuất hoặc chồng chéo, dẫn đến độ chính xác nhận diện suy giảm. Để khắc phục vấn đề này, khối xử lý còn tích hợp các thuật toán xử lý ảnh bổ sung như Polygon Fill, Rectangle Fill, Pixel-wise Logic và Non-zero Pixel Count nhằm tính toán tỷ lệ che phủ của xe máy trong các vùng quan tâm. Trên cơ sở đó, số lượng xe máy trong từng vùng được ước lượng, góp phần nâng cao độ chính xác tổng thể của quá trình đếm phương tiện.
    \item \textbf{Khối dự báo lưu lượng và điều chỉnh tín hiệu đèn giao thông: } None
    \item \textbf{Khối mô phỏng: } Sử dụng phần mềm SUMO để tái hiện mạng lưới giao thông thực tế. Khối này tiếp nhận hạ tầng từ OSM và luồng phương tiện từ khối dự báo để thực hiện các kịch bản mô phỏng giao thông vi mô, phục vụ việc đánh giá chiến lược điều phối.
    \item \textbf{Khối hiển thị và đánh giá kết quả: } Cung cấp giao diện đồ họa (Dashboard) để người dùng theo dõi trạng thái giao thông thời gian thực, quản lý các kịch bản mô phỏng thông qua Scenario Explorer và xuất ra các biểu đồ đánh giá hiệu quả (Waiting Time, Mean Speed).
\end{itemize}

\subsection{Thiết kế khối thu thập dữ liệu}
Khối thu thập dữ liệu đảm nhiện việc tự động truy suất và tải về các hình ảnh snapshot từ website camera giao thông công khai của thành phố Hồ Chí Minh (giaothong.hochiminhcity.gov.vn) rồi sau đó đẩy dữ liệu thu thập được lên khối lưu trữ đám mây Google Drive để phục vụ cho các bước xử lý tiếp theo.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio]{fig/upload_raw_images.png}
    \caption[Lưu đồ chính cho quá trình thu thập dữ liệu]{Lưu đồ chính quá trình thu thập dữ liệu}
    \label{fig:upload_raw_images}
\end{figure}

Giải thích lưu đồ thu thập dữ liệu ở hình \ref{fig:upload_raw_images}: \\
\hspace*{1cm} Quá trình thu thập dữ liệu bắt đầu bằng việc khởi tạo Google Drive API để kết nối và thao tác với hệ thống lữu trữ đám mây. Tiếp theo, hệ thống sẽ khởi tạo một hàng đợi (drive\_queue) dùng để làm queue trung gian để giao tiếp giữa các tiến trình và một bộ nhớ đệm để lưu trữ mã SHA của ảnh được lưu gần nhất của mỗi camera. Sau đó, hệ thống sẽ tiến hành chạy đa luồng để thực hiện các tác vụ sau:
\begin{itemize}
    \item \textbf{Nhóm luồng truy suất camera: } Ở nhóm luồng này tùy theo số lượng camera cần giám sát là 13 camera ứng với 13 địa điểm mà hệ thống sẽ khởi tạo tương ứng số luồng. Mỗi luồng sẽ chịu trách nhiệm truy suất ảnh từ một camera cụ thể. Sau đó, cứ mỗi khoảng thời gian nhất định là khoảng 5 phút thì ảnh sẽ được gom lại và gửi vào hàng đợi drive\_queue để chờ được tải lên Google Drive.
    \item \textbf{Luồng chính: } Luồng này khởi tạo 2 nhóm luồng truy suất camera và nhóm luồng upload dữ liệu lên Drive. Ngoài ra, luồng này có đóng vai trò như một bộ điều phối, chịu trách nhiệm phân loại và giao task cho nhóm luồng upload ảnh lên Google Drive.
    \item \textbf{Nhóm luồng upload dữ liệu lên Drive: } Nhóm luồng này bao gồm 2 luồng chạy song song, chịu trách nhiệm nhận task để đẩy ảnh từ hàng đợi lên Google Drive.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.7\textheight, keepaspectratio]{fig/main_threading.png}
    \caption[Lưu đồ chi tiết hoạt động của luồng chính]{Lưu đồ chi tiết hoạt động của luồng chính}
    \label{fig:main_threading}
\end{figure}

Giải thích lưu đồ chi tiết hoạt động của luồng chính ở hình \ref{fig:main_threading}: \\
\hspace*{1cm} Luồng chính bắt đầu bằng việc khởi tạo nhóm luồng truy suất camera và nhóm luồng upload cùng với cơ chế đồng bộ hóa. Sau đó, luồng chính đi vào một vòng lặp liên tục chờ nhận công việc từ hàng đợi drive\_queue. Nếu hàng đợi không có task, luồng sẽ nghỉ 0.1 giây rồi tiếp tục kiểm tra. Khi nhận được task, luồng chính sẽ xác định loại công việc: nếu là task tạo thư mục, luồng kiểm tra thư mục camera đã tồn tại chưa và tiến hành tạo trên Google Drive nếu chưa có; nếu là task upload ảnh, luồng chuẩn bị thông tin và phân phối công việc cho nhóm luồng upload. Vòng lặp này tiếp tục cho đến khi nhận được tín hiệu ngắt từ người dùng, lúc đó luồng chính sẽ gửi tín hiệu dừng đến tất cả các luồng con, chờ chúng hoàn thành công việc, rồi kết thúc chương trình.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio]{fig/camera_threading.png}
    \caption[Lưu đồ chi tiết hoạt động của nhóm luồng truy suất camera]{Lưu đồ chi tiết quá trình truy suất ảnh từ camera trên website}
    \label{fig:camera_threading}
\end{figure}

Giải thích lưu đồ chi tiết hoạt động của nhóm luồng truy suất camera ở hình \ref{fig:camera_threading}: \\
\hspace*{1cm} Luồng giám sát camera bắt đầu bằng việc khởi tạo batch buffer - một bộ đệm dùng để gom nhóm các ảnh trước khi upload - sau đó gửi một task thông qua drive\_queue để yêu cầu tạo folder cho camera trên Google Drive. Sau bước khởi tạo, hệ thống đi vào vòng lặp chính. Đầu tiên, hệ thống kiểm tra xem đang ở trạng thái hoạt động hay không. Nếu không hoạt động, hệ thống sẽ kiểm tra thời điểm hiện tại có nằm trong khung giờ cho phép hay không; nếu không thì ngủ 4 giây rồi quay lại đầu vòng lặp, nếu có thì chuyển sang trạng thái hoạt động. Khi đã ở trạng thái hoạt động, hệ thống gửi yêu cầu HTTP để lấy ảnh từ camera trên website giaothong.hochiminhcity.gov.vn.

Nếu việc lấy ảnh thất bại, hệ thống quay lại đầu vòng lặp để thử lại. Nếu thành công, hệ thống tính toán mã SHA của ảnh vừa lấy và so sánh với mã SHA của ảnh trước đó đã được lưu trong bộ nhớ đệm. Việc so sánh này nhằm phát hiện ảnh mới có thực sự khác biệt hay không, tránh lưu trữ các ảnh trùng lặp. Nếu mã SHA không thay đổi, nghĩa là ảnh giống ảnh cũ, hệ thống bỏ qua và quay lại vòng lặp. Nếu mã SHA khác nhau, hệ thống tiếp tục kiểm tra xem thời điểm ảnh được chụp có nằm trong khung giờ cho phép hay không. Nếu không nằm trong khung giờ, hệ thống chuyển về trạng thái không hoạt động và quay lại đầu vòng lặp.

Khi ảnh mới hợp lệ (SHA khác và trong khung giờ), hệ thống cập nhật mã SHA mới vào bộ nhớ đệm và thêm ảnh vào batch buffer. Tiếp theo, hệ thống kiểm tra xem batch buffer đã gom đủ ảnh trong khoảng thời gian 5 phút hay chưa. Nếu chưa đủ, hệ thống ngủ 4 giây rồi tiếp tục vòng lặp để lấy thêm ảnh. Nếu đã đủ, hệ thống đẩy toàn bộ ảnh trong batch qua drive\_queue để upload lên Google Drive, sau đó xóa batch buffer hiện tại và tiếp tục ngủ 4 giây trước khi bắt đầu chu kỳ mới. Vòng lặp này tiếp tục cho đến khi người dùng thực hiện ngắt (Ctrl+C), lúc đó hệ thống sẽ xóa batch buffer còn lại và kết thúc tiến trình.





\subsection{Thiết kế khối lưu trữ}
Khối lưu trữ dữ liệu đóng vai trò tiếp nhận, tổ chức và quản lý toàn bộ dữ liệu trong hệ thống, bao gồm ảnh snapshot thu thập từ camera giao thông, dữ liệu sau tiền xử lý, kết quả nhận diện - đếm phương tiện, cũng như các tập dữ liệu đầu vào/đầu ra phục vụ mô phỏng và dự báo. Trong đề tài này, Google Drive được sử dụng như một nền tảng lưu trữ đám mây, đáp ứng yêu cầu về dung lượng, khả năng truy cập linh hoạt và thuận tiện cho việc chia sẻ, sao lưu dữ liệu trong quá trình nghiên cứu.

Việc sử dụng Google Drive cho phép hệ thống tách biệt hoàn toàn giữa khâu xử lý và khâu lưu trữ, từ đó giảm phụ thuộc vào hạ tầng máy chủ cục bộ và tăng tính linh hoạt trong quá trình mở rộng hoặc thay đổi môi trường triển khai. Khối lưu trữ không thực hiện các chức năng xử lý dữ liệu phức tạp mà chỉ đảm nhiệm vai trò lưu trữ tệp và cung cấp dữ liệu cho các khối xử lý tiếp theo thông qua các script truy xuất tự động.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.5\textheight, keepaspectratio]{fig/file_structure.png}
    \caption[Cấu trúc lưu trữ dữ liệu trên Google Drive]{Cấu trúc lưu trữ dữ liệu trên Google Drive}
    \label{fig:file_structure}
\end{figure}

Như trên hình \ref{fig:file_structure}, dữ liệu được tổ chức theo mô hình cây phân cấp, trong đó:
\begin{itemize}
    \item \textbf{DATN\_Image\_Traffic:} 
    Thư mục chủ đạo chứa dữ liệu đầu vào thô và dữ liệu đã qua xử lý, chia làm hai nhánh chính:
    
    \begin{itemize}
        \item \textbf{Raw Images:} 
        Dữ liệu đầu vào thu thập trực tiếp từ camera giao thông (giaothong.hochiminhcity.gov.vn). Cấu trúc gồm:
        \begin{itemize}
            \item \textbf{Location Folder:} Tên thư mục theo địa điểm thực tế (Ví dụ: \texttt{Nga\_Tu\_So}, \texttt{Cau\_Giay}).
            \item \textbf{Date Folder:} Phân loại theo ngày thu thập (Định dạng: \texttt{YYYY-MM-DD}).
            \item \textbf{Hour Folder:} Phân loại theo khung giờ (Ví dụ: \texttt{01h}, \texttt{02h}...).
            \item \textbf{[Unix\_Timestamp].jpg:} Các tệp ảnh gốc với tên là Unix Timestamp để đảm bảo tính duy nhất và tự động sắp xếp theo thời gian.
        \end{itemize}

        \item \textbf{Results:} 
        Lưu trữ kết quả sau khi xử lý/nhận diện, duy trì cấu trúc tương tự nhánh Raw Images để dễ dàng đối chiếu:
        \begin{itemize}
            \item \textbf{[Unix\_Timestamp].csv:} Tệp tin chứa nhãn (labels) hoặc metadata tương ứng với ảnh gốc.
            \item \textbf{[Hour].rar:} Tệp nén toàn bộ dữ liệu của khung giờ đó để tối ưu lưu trữ.
            \item \textbf{[YYYYMMDD\_HHmmss].jpg:} Ảnh kết quả (đã vẽ bounding box...) đặt tên theo định dạng thời gian truyền thống để người dùng dễ đọc bằng mắt thường.
        \end{itemize}
    \end{itemize}
\end{itemize}


\subsection{Thiết kế khối tiền xử lý ảnh}
Khối tiền xử lý ảnh có vai trò chuẩn hóa và nâng cao chất lượng đầu vào trước khi đưa vào khối nhận diện và phân tích phương tiện. Hệ thống thực hiện các bước tiền xử lý chính sau:
\begin{enumerate}
    \item \textbf{Tăng cường độ phân giải và chuẩn hóa kích thước ảnh: } Sử dụng Real-ESRGAN để nâng cao độ phân giải và giảm nhiễu cho các ảnh snapshot, ngoài ra còn tăng kích thước ảnh về chuẩn cố định nhằm đảm bảo tính nhất quán và cải thiện khả năng nhận diện của mô hình học sâu.
    \item \textbf{Chia đều ảnh thành các phần: }Ảnh sau khi được nâng cao chất lượng được chia thành bốn vùng con có kích thước bằng nhau. Việc chia nhỏ ảnh giúp mô hình tập trung tốt hơn vào các đặc trưng cục bộ, từ đó nâng cao độ chính xác trong việc phát hiện phương tiện, đặc biệt trong các tình huống mật độ giao thông cao hoặc khi các đối tượng bị che khuất một phần.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/upscale_image.png}
    \caption[Lưu đồ quá trình tiền xử lý ảnh]{Lưu đồ chi tiết quá trình tiền xử lý ảnh}
    \label{fig:upscale_image}
\end{figure}

Giải thích lưu đồ tiền xử lý ảnh ở hình \ref{fig:upscale_image}: \\
\hspace*{1cm} Ảnh đầu vào trước hết được đưa vào mô hình Real-ESRGAN đã được huấn luyện sẵn (pre-trained model) với các tham số cấu hình gồm hệ số phóng đại $scale=2$, mô hình \textit{RealESRGAN\_x2plus}, thiết bị xử lý \textit{cuda} và chế độ tính toán bán chính xác \textit{fp16}.

Sau khi quá trình nâng cao độ phân giải hoàn tất, chất lượng ảnh đầu ra được đánh giá thông qua việc tính toán giá trị độ sáng trung bình của các pixel trong ảnh. 
Nếu giá trị này nhỏ hơn một ngưỡng xác định (cụ thể là 5), ảnh được xem là không hợp lệ do quá tối và có khả năng phát sinh lỗi trong quá trình upscale. 
Trong trường hợp này, hệ thống tiến hành thực hiện lại bước nâng cao độ phân giải với cấu hình tương tự, nhưng chuyển sang chế độ tính toán toàn chính xác (\textit{fp32}) nhằm tăng độ ổn định và độ chính xác của kết quả.

Ngược lại, nếu ảnh đầu ra đạt yêu cầu về độ sáng, ảnh sẽ được chia thành bốn vùng con có kích thước bằng nhau. 
Quá trình này được thực hiện bằng cách xác định tọa độ trung điểm theo chiều rộng và chiều cao của ảnh, từ đó cắt ảnh thành bốn phần tương ứng với các góc \textit{Top-Left}, \textit{Top-Right}, \textit{Bottom-Left} và \textit{Bottom-Right}.

Cuối cùng, các ảnh con sau khi chia không được lưu dưới dạng các tệp ảnh riêng lẻ, mà được lưu trữ dưới dạng các giá trị trong bộ nhớ cùng với các id để nhận biết được các phần ảnh để phục vụ cho quá trình nhận diện và phân tích phuwogn tiện ở khối tiếp theo.

\subsection{Thiết kế khối nhận diện và phân tích phương tiện}
Khối nhận diện và phân tích phương tiện sử dụng mô hình học sâu YOLOv11 đã được huấn luyện trước trên dataset COCO (pre-trained model) để phát hiện và phân loại các phương tiện giao thông trong từng ảnh snapshot. Tuy nhiên, bởi vì dữ liệu đầu vào có chất lượng không tốt, góc quay không tối ưu và mật độ giao thông cao, việc nhận diện chính xác các phương tiện, đặc biệt là xe máy trở nên khó khăn. Do đó, ngoài việc sử dụng mô hình YOLOv11 để phát hiện và phân loại phương tiện thì cần có thêm các bước xử lý ảnh bổ sung nhằm nâng nâng cao độ chính xác trong việc đếm xe máy, tính toán tỷ lệ che phủ của xe máy trong các vùng quan tâm (ROI - Region of Interest).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/vehicle_detector.png}
    \caption[Lưu đồ quá trình nhận diện và đếm phương tiện]{Lưu đồ quá trình nhận diện và đếm phương tiện}
    \label{fig:vehicle_detector}
\end{figure}

Giải thích lưu đồ nhận diện và đếm phương tiện ở hình \ref{fig:vehicle_detector}: \\
\hspace*{1cm} Khối này bắt đầu bằng việc tiếp nhận chính xác bốn ảnh con đã được tiền xử lý từ khối trước và tiến hành xử lý lần lượt từng ảnh. Trước hết, hệ thống kiểm tra xem ảnh con đầu vào có thuộc danh sách các Tile ID được cấu hình phân vùng ROI (Region of Interest) hay không. Nếu ảnh không nằm trong danh sách này, ảnh sẽ được đưa trực tiếp vào mô hình YOLOv11 để thực hiện phát hiện và phân loại các phương tiện, bao gồm xe hai bánh và xe bốn bánh. Ngược lại, nếu ảnh con thuộc một Tile ID có cấu hình phân vùng ROI, ảnh sẽ được xử lý bổ sung bằng các thuật toán xử lý ảnh nhằm ước lượng số lượng xe máy trong vùng quan tâm, đồng thời vẫn thực hiện nhận diện phương tiện bằng mô hình YOLOv11.
Sau khi hoàn tất quá trình xử lý đối với cả bốn ảnh con, các kết quả đếm phương tiện theo từng phần ảnh được tổng hợp lại.
Hệ thống tiếp tục kiểm tra sự trùng lặp của các phương tiện xuất hiện tại vùng rìa giữa các ảnh con và loại bỏ các trường hợp bị đếm trùng. Cuối cùng, kết quả tổng hợp được lưu trữ dưới dạng tệp csv. Đồng thời, các ảnh con được ghép lại để tạo thành ảnh kết quả, trong đó các phương tiện được phát hiện được biểu diễn bằng các bounding box, kèm theo phần che phủ của xe máy trong các vùng phân đoạn (nếu có).

Đối với việc chọn vùng quan tâm (ROI) để ước lượng số lượng xe máy thì trong đề tài này chỉ lựa chọn các vùng có mật độ xe máy cao và thường bị che khuất trong ảnh snapshot gốc. Các vùng phân đoạn được xác định thông qua một công cụ hỗ trợ được xây dựng riêng bằng Python. Công cụ này cho phép người vận hành khoanh vùng các khu vực cần khai thác trên ảnh,sau đó xuất ra tọa độ các điểm biên của vùng ROI theo hệ tọa độ pixel của ảnh. Các tọa độ ROI được biểu diễn dưới dạng các cặp điểm $(x, y)$ trong hệ tọa độ ảnh, tuân theo quy ước của thư viện OpenCV, với gốc tọa độ nằm tại góc trên bên trái ảnh. Những thông tin này được lưu trữ trong tệp cấu hình YAML tương ứng với từng địa điểm và được hệ thống sử dụng trong quá trình xử lý và phân tích ảnh như hình \ref{fig:segment_config}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/segment_config.png}
    \caption[Cấu trúc file YAML cấu hình vùng quan tâm (ROI)]{Cấu trúc file YAML cấu hình vùng quan tâm (ROI)}
    \label{fig:segment_config}
\end{figure}

Ngoài ra đối với các vùng có vật cản hoặc có yếu tố gây nhiễu trong vùng segment như bóng cây, biển quảng cáo, cột đèn... thì trong đề tài này còn cấu hình thêm các ROI để loại bỏ các yếu tố nhiễu này nhằm tránh ảnh hưởng đến kết quả đếm phương tiện như \textit{exclusion\_zones} trên hình \ref{fig:segment_config}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/process_quadrant_1.png}
    \caption[Lưu đồ xử lý từng ảnh con]{Lưu đồ xử lý từng ảnh con}
    \label{fig:process_quadrant}
\end{figure}

Giải thích lưu đồ xử lý từng ảnh con ở hình \ref{fig:process_quadrant}: \\
\hspace*{1cm}Trước hết, hệ thống nạp cấu hình phân vùng ROI (Region of Interest) từ tệp YAML đã được trình bày ở phần trước. Tiếp theo, mỗi ảnh con đầu vào được kiểm tra xem ID của phần ảnh đó có nằm trong danh sách các vùng được cấu hình ROI hay không.

Trong trường hợp ảnh con không thuộc danh sách ROI, ảnh sẽ được đưa trực tiếp vào mô hình YOLOv11 để thực hiện phát hiện và phân loại phương tiện. Ngược lại, nếu ảnh con thuộc vùng có cấu hình ROI, các tham số tương ứng như ngưỡng tin cậy (confidence threshold), ngưỡng IOU và tọa độ vùng quan tâm sẽ được trích xuất từ cấu hình để phục vụ cho các bước xử lý tiếp theo.

Tại giai đoạn này, mô hình YOLOv11 chỉ được sử dụng để phát hiện phương tiện bốn bánh. Đối với phương tiện hai bánh, hệ thống không áp dụng trực tiếp phương pháp phát hiện dựa trên bounding box do đặc thù kích thước nhỏ, mật độ cao và hiện tượng che khuất phổ biến, dẫn đến độ chính xác thấp, số lượng phát hiện không ổn định và kết quả trực quan không phản ánh đúng mật độ thực tế trong vùng quan tâm.

Thay vào đó, số lượng xe hai bánh được ước lượng gián tiếp thông qua tỷ lệ che phủ trong vùng ROI. Cụ thể, hệ thống áp dụng một số kỹ thuật xử lý ảnh bao gồm: Polygon Fill, Rectangle Fill, các phép toán logic theo pixel và đếm số pixel khác không (Non-zero Pixel Count) nhằm xác định tỷ lệ diện tích bị che phủ bởi xe máy trong vùng quan tâm. Trên cơ sở tỷ lệ che phủ này, số lượng xe hai bánh được ước lượng tương ứng.

Cuối cùng, kết quả đếm phương tiện hai bánh và bốn bánh, tỷ lệ che phủ của xe máy, cùng với ảnh trực quan hóa được lưu trữ trong bộ nhớ sẽ được tổng hợp và trả về cho khối xử lý chính của hệ thống.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/segment_detection.png}
    \caption[Lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI]{Lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI}
    \label{fig:segment_detection}
\end{figure}

Giải thích lưu đồ nhận diện phương tiện 4 bánh có trong vùng ROI ở hình \ref{fig:segment_detection}: \\
\hspace*{1cm}Trước hết, hệ thống tạo một mặt nạ nhị phân cho vùng ROI dạng đa giác dựa trên các tọa độ được trích xuất từ tệp cấu hình YAML, nhằm xác định khu vực cần phân tích trong ảnh. Tiếp theo, mô hình YOLOv11 được sử dụng để phát hiện các phương tiện trong ảnh, với các tham số ngưỡng tin cậy và ngưỡng IOU được cấu hình trước.

Sau khi thu được kết quả phát hiện, hệ thống lần lượt duyệt qua từng đối tượng và chỉ xem xét các phương tiện thuộc lớp xe bốn bánh. Đối với mỗi phương tiện hợp lệ về mặt lớp, hệ thống tính toán tọa độ bounding box và xác định xem tâm của bounding box có nằm trong vùng ROI hay không. Các phương tiện nằm ngoài vùng quan tâm sẽ không được đưa vào các bước xử lý tiếp theo.

Đối với các phương tiện bốn bánh có tâm bounding box nằm trong vùng ROI, hệ thống tiếp tục kiểm tra độ tin cậy của dự đoán. Những đối tượng có độ tin cậy nhỏ hơn ngưỡng cấu hình sẽ bị loại bỏ. Các phương tiện thỏa mãn đầy đủ các điều kiện trên sẽ được đưa vào danh sách phương tiện hợp lệ. Danh sách này sau đó được sắp xếp theo độ tin cậy giảm dần nhằm ưu tiên giữ lại các phát hiện có độ tin cậy cao trong quá trình xử lý trùng lặp.

Tiếp theo, hệ thống thực hiện loại bỏ các phát hiện trùng lặp dựa trên ngưỡng IOU đã được cấu hình. Trong trường hợp hai bounding box có giá trị IOU vượt quá ngưỡng cho phép, đối tượng có độ tin cậy thấp hơn sẽ bị loại bỏ khỏi danh sách.

Cuối cùng, số lượng phương tiện bốn bánh hợp lệ còn lại được cộng dồn vào biến đếm tổng. Đồng thời, thông tin vị trí của các bounding box này được lưu lại để phục vụ cho việc tính toán tỷ lệ che phủ của xe hai bánh cũng như trực quan hóa kết quả trong các bước xử lý tiếp theo.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=\textheight, keepaspectratio]{fig/motorbike_coverage.png}
    \caption[Lưu đồ ước lượng số lượng xe máy trong vùng ROI]{Lưu đồ ước lượng số lượng xe máy trong vùng ROI}
    \label{fig:motorbike_coverage}
\end{figure}

Giải thích lưu đồ ước lượng số lượng xe máy trong vùng ROI ở hình \ref{fig:motorbike_coverage}: \\
\hspace*{1cm} Quy trình tính tỷ lệ che phủ của xe máy trên ảnh bắt đầu bằng việc thu thập vị trí các ô tô đã được phát hiện trong vùng quan tâm (ROI). Sau đó, hệ thống tạo mask cho vùng ROI dựa trên tọa độ các đỉnh đã được cấu hình sẵn, đồng thời tạo mask phân tích bằng cách loại trừ các vùng bị ô tô chiếm giữ ra khỏi mask ROI. Điều này đảm bảo rằng chỉ những vùng không có ô tô mới được đưa vào phân tích xe máy.

Tiếp theo, hệ thống kiểm tra diện tích vùng phân tích có lớn hơn 0 hay không. Nếu diện tích bằng 0 (tức là toàn bộ ROI đã bị ô tô che phủ hoặc ROI không hợp lệ), hệ thống sẽ gán tỷ lệ che phủ xe máy bằng 0\% và chuyển thẳng đến bước tạo ảnh trực quan hóa. Ngược lại, nếu diện tích lớn hơn 0, quy trình sẽ tiếp tục với các bước phát hiện xe máy.

Trong giai đoạn phát hiện xe máy, hệ thống áp dụng mask phân tích lên ảnh gốc và chuyển đổi sang không gian màu HSV để dễ dàng nhận diện màu sắc. Sau đó, hai phương pháp phát hiện được thực hiện song song: phát hiện các vùng có màu sắc đặc trưng của xe máy (như màu đen, xám của yên xe, khung xe) và phát hiện các cạnh đặc trưng như bánh xe, khung xe. Kết quả từ hai phương pháp này được kết hợp lại để tạo ra mask tổng hợp thể hiện vùng ước lượng là xe máy.

Trước khi tính toán diện tích, hệ thống kiểm tra xem có vùng loại trừ từ cấu hình hay không (ví dụ: vùng vỉa hè, cột đèn, hoặc các đối tượng cố định khác). Nếu có, các vùng này sẽ được loại bỏ khỏi kết quả phát hiện xe máy để đảm bảo độ chính xác.

Cuối cùng, hệ thống đếm số pixel trong vùng ước lượng là xe máy và tính tỷ lệ che phủ theo công thức: (Diện tích xe hai bánh / Diện tích ROI) x 100\%. Kết quả được trực quan hóa trên ảnh đầu ra với đường viền vùng ROI, vùng xe máy được tô màu đỏ, và thông tin tỷ lệ che phủ được hiển thị trực tiếp trên ảnh.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{fig/result_static_config.png}
    \caption[Cấu hình quy đổi diện tích che phủ sang số lượng xe hai bánh]{Cấu hình quy đổi diện tích che phủ sang số lượng xe hai bánh}
    \label{fig:result_static_config}
\end{figure}

Như hình \ref{fig:result_static_config}, hệ thống sử dụng hệ số quy đổi từ tỷ lệ che phủ sang số lượng xe hai bánh được cấu hình trong tệp YAML để ước lượng số lượng xe hai bánh trong vùng ROI. Hệ số này được xác định dựa trên việc tính toán phần trăm che phủ trung bình của một xe hai bánh trong vùng quan tâm, từ đó suy ra số lượng xe hai bánh tương ứng với tỷ lệ che phủ đo được. Kết quả khi quy đổi ra sẽ được cộng vào số lượng xe hai bánh của thời điểm đó và lưu trữ cùng với số lượng xe ô tô đã được phát hiện bởi mô hình YOLOv11.

Bước cuối cùng nhưng cũng không kém phần quan trọng, hệ thống sẽ tổng hợp các khung thời điểm về mỗi 5 phút để tạo thành chuỗi thời gian lưu lượng giao thông đồng nhất. Quá trình này bao gồm việc nhóm các bản ghi theo khoảng thời gian 5 phút, sau đó tính lượng trung bình phương tiện có trong khoảng thời gian đó. 

\subsection{Thiết kế khối dự báo lưu lượng và điều chỉnh tín hiệu đèn giao thông}
None

\subsection{Thiết kế khối mô phỏng giao thông (SUMO)}
Khối mô phỏng được thiết kế dựa trên một quy trình tự động hóa (Pipeline) tích hợp giữa dữ liệu địa không gian thực tế và các công cụ mô phỏng vi mô. Quy trình xây dựng môi trường mô phỏng bao gồm 5 giai đoạn chính:

\begin{enumerate}
    \item \textbf{Lựa chọn vùng (Location Selection):} Người dùng xác định khu vực nghiên cứu thông qua việc vẽ đa giác (Polygon) trên bản đồ tương tác. Tọa độ của đa giác này là dữ liệu đầu vào để truy xuất hạ tầng từ OpenStreetMap.
    \item \textbf{Xử lý dữ liệu OSM (OSM Processing):} Hệ thống sử dụng thư viện OSMnx để tải dữ liệu mạng lưới đường bộ. Tại giai đoạn này, một bước quan trọng là làm sạch dữ liệu (Network Cleanup) bằng cách loại bỏ các đoạn đường không phục vụ mô phỏng chính như đường hẻm nhỏ, đường cụt hoặc lối đi bộ để giảm tải tính toán (như hình \ref{fig:fig_I3_network_cleanup}).
    \item \textbf{Biên dịch mạng lưới (Network Compilation):} Dữ liệu OSM được công cụ \textit{netconvert} của SUMO biên dịch sang định dạng \texttt{.net.xml}. Giai đoạn này cũng thực hiện việc gộp các nút giao gần nhau và cấu hình hệ thống đèn tín hiệu mặc định.
    \item \textbf{Tạo luồng phương tiện (Flow Generation):} Hệ thống xác định các cạnh biên (\textit{fringe edges}) của mạng lưới để làm điểm phát sinh và điểm kết thúc của phương tiện. Luồng xe được tạo ra dựa trên tỷ lệ phân bổ phương tiện (xe máy, xe hơi) thu thập từ thực tế.
    \item \textbf{Cấu hình mô phỏng (SUMO Config):} Tổng hợp tất cả các tệp hạ tầng, lộ trình và tín hiệu vào một tệp cấu hình duy nhất (\texttt{.sumocfg}) để khởi chạy môi trường mô phỏng.
\end{enumerate}

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/fig_I3_network_cleanup.png}
        \caption[Xử lý làm sạch mạng lưới]{Xóa đường hẻm, cụt để giảm tải mô phỏng}
        \label{fig:fig_I3_network_cleanup}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/fig_I4_osm_export_sumo.png}
        \caption[Quy trình biên dịch mạng lưới]{Xuất dữ liệu OSM và biên dịch sang SUMO}
        \label{fig:fig_I4_osm_export_sumo}
    \end{minipage}
\end{figure}

\subsection{Thiết kế khối hiển thị và đánh giá kết quả}
Khối hiển thị được thiết kế là một ứng dụng web dashboard, tích hợp các công cụ hỗ trợ người dùng phân tích kịch bản giao thông:
\begin{itemize}
    \item \textbf{Scenario Explorer:} Công cụ cho phép người dùng tùy chỉnh các tham số đầu vào của mô phỏng như lưu lượng xe, tỷ lệ phương tiện và cấu hình luồng. Người dùng có thể quan sát trực quan các tuyến đường (routes) di chuyển trong mạng lưới.
    \item \textbf{SUMO Control Interface:} Giao diện điều khiển thời gian thực kết nối với lõi mô phỏng qua TraCI. Giao diện này hiển thị các thông số vận hành của nút giao (trạng thái đèn, độ trễ) và cho phép can thiệp thủ công vào quá trình điều tiết nếu cần thiết.
    \item \textbf{Công cụ đánh giá:} Sau khi kết thúc mô phỏng, hệ thống tự động trích xuất dữ liệu từ các tệp \texttt{tripinfo.xml} và \texttt{summary.xml} để tính toán các chỉ số: thời gian di chuyển trung bình (Mean Travel Time), tốc độ trung bình (Mean Speed) và tổng lượng khí thải.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/fig_II4_scenario_explorer.png}
    \caption[Giao diện Scenario Explorer]{Giao diện Scenario Explorer giúp quản lý và tùy chỉnh kịch bản}
    \label{fig:fig_II4_scenario_explorer}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/fig_II4_sumo_control.png}
    \caption[Giao diện SUMO Control]{Giao diện điều khiển và giám sát quá trình mô phỏng thực tế}
    \label{fig:fig_II4_sumo_control}
\end{figure}

